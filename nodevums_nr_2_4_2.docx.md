

| A blue flag with yellow stars  Description automatically generated A black and red text with numbers  Description automatically generated |
| --- |
| PÄ“tniecÄ«bas projekts Nr. 2.4. â€œDaudzvalodÄ«gs uzÅ†Ä“muma informÄcijas semantiskÄs meklÄ“Å¡anas un atbilÅ¾u gatavoÅ¡anas risinÄjumsâ€ |
| ID Nr.: 5.1.1.2.i.0/1/22/A/CFLA/008 |
| **2.4.2.Â PÄ“tÄ«jums par kontekstÄ balstÄ«tu jautÄjumu atbildÄ“Å¡anu** |
|  |

| 2025, RÄ«ga |
| --- |

**InformÄcija par dokumentu**

| Dokumenta numurs: | 2.4.2 |
| --- | --- |
| Dokumenta nosaukums: | PÄ“tÄ«jums par lielajos valodas modeÄ¼os balstÄ«tuÂ semantisko meklÄ“Å¡anu |
| PlÄnotais sagatavoÅ¡anas datums: | 28.02.2025. |
| Faktiskais sagatavoÅ¡anas datums: | 28.02.2025. |
| Galvenais autors: | Tilde SIA, Daiga Deksne, MÄrcis Pinnis |
| DalÄ«bnieki: | IT kompetences centrs, SIA (ITKC) |
| PÄrbaudÄ«ja: | ITKC, Dr. JÄnis VucÄns |
| AktivitÄte: | PÄ“tÄ«jums par kontekstÄ balstÄ«tu jautÄjumu atbildÄ“Å¡anu |
| PieejamÄ«ba: | KonfidenciÄls |
| Versija: | 1.0 |
| AtslÄ“gas vÄrdi: | semantiskÄ meklÄ“Å¡ana, lielie valodas modeÄ¼i, vektorizÄ“Å¡anas modeÄ¼i |

ZinÄtniskÄ virziena vadÄ«tÄjs Dr. JÄnis VucÄns

VadoÅ¡ais pÄ“tnieks Dr. MÄrcis Pinnis

*AutortiesÄ«bas Â© Tilde SIA, 2025*

*Visas tiesÄ«bas aizsargÄtas. Å Ä« dokumenta saturu vai tÄ daÄ¼as drÄ«kst jebkÄdÄ veidÄ un nolÅ«kÄ atveidot vai izplatÄ«t pÄ“c rakstiskas atÄ¼aujas saÅ†emÅ¡anas no Tilde SIA.* 

*TurpmÄk minÄ“tie produktu un uzÅ†Ä“mumu nosaukumi var bÅ«t to Ä«paÅ¡nieku preÄu zÄ«mes.*

*Sagatavots: Tilde, VienÄ«bas gatve 75A, RÄ«ga, LV-1004, Latvija*

####
**AnotÄcija**

Å is dokuments apkopo pÄ“tniecÄ«bas projektaâ€¯â€œDaudzvalodÄ«gs uzÅ†Ä“muma informÄcijas semantiskÄs meklÄ“Å¡anas un atbilÅ¾u gatavoÅ¡anas risinÄjumsâ€ aktivitÄtesâ€¯â€œ2.4.2.Â PÄ“tÄ«jums par kontekstÄ balstÄ«tu jautÄjumu atbildÄ“Å¡anuâ€â€¯gaitu, rezultÄtus un galvenos secinÄjumus. AktivitÄtÄ“ tika veikti eksperimenti ar uzvedÅ†u modelÄ“Å¡anu daÅ¾Ädiem uzdevumiem, tostarp tulkoÅ¡anai, tekstu klasificÄ“Å¡anai, SQL vaicÄjumu Ä£enerÄ“Å¡anai un informÄcijas izguvei. Tika analizÄ“tas lielo valodas modeÄ¼u, piemÄ“ram, GPT, Llama, Mistral, Gemma un Phi, spÄ“jas Ä£enerÄ“t atbildes un tulkot starp angÄ¼u, latvieÅ¡u, lietuvieÅ¡u, igauÅ†u un Äehu valodÄm. TÄpat tika izveidota wiki datu kopa, kas Ä¼Äva testÄ“t kontekstÄ balstÄ«tu atbilÅ¾u kvalitÄti vairÄkÄs valodÄs. PÄ“tÄ«juma rezultÄti sniedz salÄ«dzinoÅ¡u analÄ«zi par daÅ¾Ädu lielo valodas modeÄ¼u efektivitÄti un kvalitÄti. Gan tulkoÅ¡anas uzdevumam, gan atbildes Ä£enerÄ“Å¡anai visnoderÄ«gÄkais ir OpenAI GPT-4o modelis, bet arÄ« brÄ«vpieejas modeÄ¼i, Ä«paÅ¡i Gemma2:27b un Llama3.1:70b, uzrÄda labus rezultÄtus pÄrbaudÄ«tajos NLP uzdevumos un valodÄs.

####
**Abstract**

This document summarizes the progress, results, and key conclusions of the research activity â€œ2.4.2. Study on context-based question answering,â€ conducted as part of the project â€œMultilingual Enterprise Information Semantic Search and Answer Generation Solution.â€ The activity identified and developed methods applicable to context-based question answering. The activity involved conducting experiments with prompt modeling for various tasks, including translation, text classification, SQL query generation, and information retrieval. The capabilities of large language models such as GPT, Llama, Mistral, Gemma, and Phi were analyzed in generating responses and translating between English, Latvian, Lithuanian, Estonian, and Czech. Additionally, a wiki dataset was created to test the quality of context-based responses across multiple languages. The research results provide a comparative analysis of the efficiency and quality of different large language models. For both translation tasks and response generation, the most useful model is OpenAI's GPT-4o, while open-access models, particularly Gemma2:27b and Llama3.1:70b, also demonstrate strong performance in the tested NLP tasks and languages.

Saturs

[Saturs 5](#_Toc191629983)

[1 Ievads 6](#_Toc191629984)

[2 Termini un saÄ«sinÄjumi 7](#_Toc191629985)

[3 UzvedÅ†u izmantoÅ¡ana atbilÅ¾u Ä£enerÄ“Å¡anÄ 8](#_Toc191629986)

[3.1 UzvedÅ†u lietojums un veidi 8](#_Toc191629987)

[3.2 RAG uzvednes ar ietvertu konteksta informÄciju 9](#_Toc191629988)

[3.3 JautÄjumu klasificÄ“Å¡anai izmantojamÄs uzvednes 9](#_Toc191629989)

[3.4 Uzvedne kopsavilkuma Ä£enerÄ“Å¡anai 10](#_Toc191629990)

[3.5 Uzvednes tabulÄru datu izmantoÅ¡anai 10](#_Toc191629991)

[4 Eksperimentos izmantotie lielie valodas modeÄ¼i 13](#_Toc191629992)

[5 Teksta tulkoÅ¡ana ar lielo valodas modeÄ¼u palÄ«dzÄ«bu 14](#_Toc191629993)

[6 KontekstÄ balstÄ«tu atbilÅ¾u Ä£enerÄ“Å¡ana daÅ¾ÄdÄs valodÄs 18](#_Toc191629994)

[7 DaÅ¾Ädu lielo valodas modeÄ¼u atbilÅ¾u Ä£enerÄ“Å¡anas kvalitÄtes salÄ«dzinÄjums 22](#_Toc191629995)

[7.1 Atbildes izvÄ“le no vairÄkiem variantiem 22](#_Toc191629996)

[7.2 Atbildes Ä£enerÄ“Å¡ana, izmantojot modeÄ¼a iekÅ¡Ä“jÄs zinÄÅ¡anas 23](#_Toc191629997)

[8 SecinÄjumi 26](#_Toc191629998)

[9 IzmantotÄs literatÅ«ras saraksts 27](#_Toc191629999)

1. Ievads

KontekstÄ balstÄ«tas informÄcijas semantiskÄs meklÄ“Å¡anas un atbilÅ¾u Ä£enerÄ“Å¡anas sistÄ“mas izveidei piemÄ“rota ir izguvÄ“ balstÄ«tas Ä£enerÄ“Å¡anas (RAG) pieeja, kas apvieno informÄcijas izgÅ«Å¡anas iespÄ“jas no zinÄÅ¡anu avotiem, kurus ir iespÄ“jams papildinÄt, ar lielo valodas modeÄ¼u (LLM) iespÄ“jÄm. LLM paÄ¼aujas uz iepriekÅ¡ apgÅ«tu zinÄÅ¡anu kopumu. RAG pieeja Ä¼auj modeÄ¼iem dinamiski piekÄ¼Å«t ÄrÄ“jÄm datubÄzÄ“m, dokumentiem vai citÄm informÄcijas krÄtuvÄ“m. Atbildes tiek veidotas, Å†emot vÄ“rÄ ne tikai modeÄ¼a iekÅ¡Ä“jo zinÄÅ¡anu bÄzi, bet arÄ« reÄllaikÄ iegÅ«tu un kontekstam atbilstoÅ¡u informÄciju.

MÅ«su mÄ“rÄ·is ir uzlabot vienkÄrÅ¡oto RAG bÄzes risinÄjumu, iekÄ¼aujot virkni jaunu metoÅ¾u, kas Ä¼auj risinÄjumam sasniegt labus rezultÄtus neatkarÄ«gi no nozares un valodas, kÄdÄ ir konteksta dati un kÄdÄ lietotÄjs uzdod jautÄjumu.

1. aktivitÄtÄ“ tika pÄ“tÄ«tas metodes, kas saistÄ«tas ar jautÄjumam atbilstoÅ¡a konteksta izguvi. 2. aktivitÄtÄ“ â€œPÄ“tÄ«jums par kontekstÄ balstÄ«tu jautÄjumu atbildÄ“Å¡anuâ€ tiek aplÅ«koti jautÄjumi, kas saistÄ«ti ar atbildes Ä£enerÄ“Å¡anu. Å ajÄ aktivitÄtÄ“ tika izvirzÄ«ti Å¡Ädi uzdevumi:

1. izpÄ“tÄ«t un modelÄ“t efektÄ«vas vaicÄjumu uzvednes, lai nodroÅ¡inÄtu kontekstÄ balstÄ«tu atbilÅ¾u Ä£enerÄ“Å¡anu daÅ¾ÄdÄs valodÄs;
2. izpÄ“tÄ«t un izstrÄdÄt metodes teksta tulkoÅ¡anai ar lielo valodas modeÄ¼u palÄ«dzÄ«bu daudzvalodÄ«bas iespÄ“joÅ¡anai;
3. izpÄ“tÄ«t lielo valodas modeÄ¼u spÄ“jas Ä£enerÄ“t dabiskÄs valodas atbildes daÅ¾ÄdÄs valodÄs lietotÄju vaicÄjumiem saistÄ«bÄ ar organizÄcijas darbÄ«bu;
4. salÄ«dzinÄt daÅ¾Ädu lielo valodas modeÄ¼u spÄ“jas Ä£enerÄ“t atbildes iekÅ¡Ä“jo zinÄÅ¡anu mÄkslÄ«gÄ intelekta sistÄ“mas lietojumÄ.

Lai Ä«stenotu Å¡os uzdevumus, esam veikuÅ¡i eksperimentus ar uzvedÅ†u Ä£enerÄ“Å¡anu. Uzvednes eksperimentos tiek izmantotas daÅ¾Ädiem uzdevumiem â€“ tulkoÅ¡anai, tekstu klasificÄ“Å¡anai, SQL vaicÄjumu Ä£enerÄ“Å¡anai, informÄcijas vienÄ«bu izguvei no teksta, atbildes Ä£enerÄ“Å¡anai saskaÅ†Ä ar kontekstu. Esam pÄrbaudÄ«juÅ¡i lielo valodas modeÄ¼u tulkoÅ¡anas iespÄ“jas daÅ¾Ädiem GPT, Llama, Mistral, Gemma un Phi modeÄ¼iem, tulkojot no angÄ¼u uz latvieÅ¡u, lietuvieÅ¡u, igauÅ†u un Äehu valodÄm un no Å¡Ä«m valodÄm uz angÄ¼u valodu. Esam izveidojuÅ¡i *wiki* datu kopu, ar kuru ir pÄrbaudÄ«ta kontekstÄ balstÄ«tu atbilÅ¾u Ä£enerÄ“Å¡ana angÄ¼u, latvieÅ¡u, lietuvieÅ¡u un igauÅ†u valodÄs. Esam pÄrbaudÄ«juÅ¡i daÅ¾Ädu lokÄli uzstÄdÄmu brÄ«vpieejas modeÄ¼u un komerciÄlo OpenAI modeÄ¼u kvalitÄti.

Nodevums â€œPÄ“tÄ«jums par kontekstÄ balstÄ«tu jautÄjumu atbildÄ“Å¡anuâ€ ir sagatavots un izmantojams saskaÅ†Ä ar projekta â€œInformÄcijas un komunikÄcijas tehnoloÄ£iju kompetences centrsâ€, ID: 5.1.1.2.i.0/1/22/A/CFLA/008 pÄ“tniecÄ«bas projektu Nr. 2.4 â€œDaudzvalodÄ«gs uzÅ†Ä“muma informÄcijas semantiskÄs meklÄ“Å¡anas un atbilÅ¾u gatavoÅ¡anas risinÄjumsâ€, kas tiek Ä«stenots, izmantojot piesaistÄ«to AtveseÄ¼oÅ¡anas fonda lÄ«dzfinansÄ“jumu saskaÅ†Ä ar 05.07.2022. MK noteikumiem Nr.418 DarbÄ«bas programmas â€œLatvijas AtveseÄ¼oÅ¡anas un noturÄ«bas mehÄnisma plÄna 5.1.r. reformu un investÄ«ciju virziena "ProduktivitÄtes paaugstinÄÅ¡ana caur investÄ«ciju apjoma palielinÄÅ¡anu P&A" 5.1.1.r. reformas "InovÄciju pÄrvaldÄ«ba un privÄto P&A investÄ«ciju motivÄcija" 5.1.1.2.i. investÄ«cijas "Atbalsta instruments inovÄciju klasteru attÄ«stÄ«bai" Ä«stenoÅ¡anas noteikumi kompetences centru ietvarosâ€ ietvaros.

1. Termini un saÄ«sinÄjumi

DokumentÄ lietoti specifiski termini, kuru detalizÄ“ts skaidrojums Å¡ajÄ dokumentÄ nav dots. Nereti Å¡iem terminiem nav plaÅ¡i lietota tulkojuma latvieÅ¡u valodÄ, tÄpÄ“c, lai bÅ«tu vieglÄk atrast atbilsmi starp Å¡ajÄ dokumentÄ lietotajiem latvieÅ¡u valodas terminiem un izmantotajos avotos lietotajiem angÄ¼u valodas terminiem, Å¡ajÄ dokumentÄ ir iekÄ¼auts izmantoto terminu saraksts (skat. 1. tabulu) ar to tulkojumiem angÄ¼u valodÄ.

1. tabula. Izmantoto terminu un to tulkojumu saraksts

| **Termins angliski** | **Termins latviski** | **SaÄ«sinÄjums** |
| --- | --- | --- |
| answer relevance | atbildes atbilstÄ«ba |  |
| Bilingual Evaluation Understudy | divvalodu novÄ“rtÄ“jums | BLEU |
| Cross-lingual Optimized Metric for Evaluation of Translation | InterlingvÄli optimizÄ“ta metrika tulkoÅ¡anas vÄ“rtÄ“Å¡anai | COMET |
| context relevance | konteksta atbilstÄ«ba |  |
| corpus | korpuss |  |
| cosine distance | kosinusa attÄlums |  |
| cosine similarity | kosinusa lÄ«dzÄ«ba |  |
| character F-score | rakstzÄ«mes F mÄ“rs | ChrF |
| faithfulness | uzticamÄ«ba |  |
| keyword | atslÄ“gvÄrds |  |
| large language model | lielais valodas modelis | LLM |
| Levenshtein distance | LevenÅ¡teina attÄlums |  |
| prompt | uzvedne |  |
| precision | precizitÄte |  |
| recall | pÄrklÄjums |  |
| retrieval-augmented generation | izguvÄ“ balstÄ«ta Ä£enerÄ“Å¡ana | RAG |
| Recall-Oriented Understudy for Gisting Evaluation | uz pÄrklÄjumu vÄ“rsta pamatpÄ“tÄ«juma vÄ“rtÄ“Å¡ana | ROUGE |
| Translation Edit Rate | tulkoÅ¡anas kÄ¼Å«du Ä«patsvars | TER |
| zero-shot prompt | bezpiemÄ“ru uzvedne |  |
| few-shot prompt | vairÄkpiemÄ“ru uzvedne |  |
| chain of thought | sprieÅ¡anas Ä·Ä“de |  |

1. UzvedÅ†u izmantoÅ¡ana atbilÅ¾u Ä£enerÄ“Å¡anÄ
   1. UzvedÅ†u lietojums un veidi

IzguvÄ“ balstÄ«tas Ä£enerÄ“Å¡anas pieejas otrajÄ solÄ« (skatÄ«t 1. attÄ“lu), kas veic atbildes Ä£enerÄ“Å¡anu, svarÄ«ga loma ir uzvednes veidoÅ¡anai. Uzvedne ir viss datu kopums, kas tiek padots Ä£eneratÄ«vÄ valodas modeÄ¼a ievaddatos, uz kÄ pamata Ä£eneratÄ«vais valodas modelis Ä£enerÄ“ atbildi (Schulhoff et al., 2024). Uzvedne sniedz norÄdÄ«jumus lielajam valodas modelim, kÄdai ir jÄbÅ«t atbildei uz lietotÄja uzdoto jautÄjumu. Lielie valodas modeÄ¼i ir jutÄ«gi pret nelielÄm variÄcijÄm uzvedÅ†u formulÄ“jumÄ, tÄdÄ“Ä¼ problÄ“mai atbilstoÅ¡u uzvedÅ†u Ä£enerÄ“Å¡ana nav vienkÄrÅ¡s uzdevums. Ar uzvedni ir iespÄ“jams regulÄ“t, kÄdai ir jÄbÅ«t atbildes struktÅ«rai, garumam un atbildes valodas stilam. Uzvednes tiek lietotas nevien RAG risinÄjumos, bet arÄ« citu uzdevumu veikÅ¡anai, piemÄ“ram, kopsavilkumu Ä£enerÄ“Å¡anai, tulkoÅ¡anai, klasificÄ“Å¡anai, vÄ“rtÄ“Å¡anai, programmu koda Ä£enerÄ“Å¡anai utt.


![](figures/0)


1. attÄ“ls. SemantiskÄ indeksÄ“Å¡ana un izguvÄ“ balstÄ«tas Ä£enerÄ“Å¡anas divi soÄ¼i â€“ dokumentu atraÅ¡ana un (kontekstÄ balstÄ«ta) jautÄjumu atbildÄ“Å¡ana

UzvedÅ†u izveidÄ“ tiek izmantoti daÅ¾Ädi paÅ†Ä“mieni. Ir bezpiemÄ“ru uzvednes, vairÄkpiemÄ“ru uzvednes, sprieÅ¡anas Ä·Ä“des uzvednes, ar konteksta informÄciju papildinÄtas uzvednes un citas (Sahoo et al., 2024). **BezpiemÄ“ru uzvednÄ“s** tiek ietvertas instrukcijas, bet nav piemÄ“ru, kas parÄda, kÄdu atbildi LLM jÄatgrieÅ¾, ja ievadÄ“ ir konkrÄ“ti dati. Modelis tikai seko instrukcijÄm un izmanto zinÄÅ¡anas, kas ir paÅ¡Ä modelÄ« (Radford et al., 2019). **VairÄkpiemÄ“ru uzvednÄ“s** ir ietverts viens vai vairÄki piemÄ“ri ar sagaidÄmajÄm atbildÄ“m. Å Äda informÄcija modelim palÄ«dz labÄk saprast uzdevumu, taÄu var arÄ« izmainÄ«t modeÄ¼a uzvedÄ«bu, Ä£enerÄ“tajÄ atbildÄ“ dodot priekÅ¡roku bieÅ¾Äk sastaptiem vÄrdiem (Brown et al., 2020). **SprieÅ¡anas Ä·Ä“des uzvednÄ“s** risinÄmais uzdevums tiek sadalÄ«ts sÄ«kÄk pa soÄ¼iem, aprakstot katru soli, kuru veicot noteiktÄ secÄ«bÄ, var nonÄkt pie vÄ“lamÄ gala rezultÄta (Wei et al., 2022).

* 1. RAG uzvednes ar ietvertu konteksta informÄciju

MÅ«su RAG risinÄjumÄ atbilde tiek Ä£enerÄ“ta, izmantojot Å¡Ädu uzvedni angÄ¼u valodÄ (â€œ{context\_str}â€ tiek aizvietots ar konteksta fragmentiem):

Answer ONLY with the facts listed in the provided context in question language. Your goal is to provide accurate and relevant answers based on the facts in the provided context. Avoid making assumptions or adding personal opinions. Emphasize the use of facts listed in the provided context documents. Avoid generating speculative or generalized information.

Context information is below.  
---------------------  
{context\_str}  
---------------------  
Instructions: Given the context information and chat history and without any other prior knowledge, answer the question.

If there is no answer found in context honestly answer with a single sentence: 'The context does not provide an answer to the question.'

Uzvedne detalizÄ“ti apraksta, kÄdai ir jÄbÅ«t atbildei, kÄdu informÄciju tajÄ drÄ«kst izmantot, ko darÄ«t, ja noderÄ«gas informÄcijas kontekstÄ nav. Lai gan uzvedne ir angÄ¼u valodÄ, to var izmantot daÅ¾ÄdÄm valodÄm. UzvednÄ“ norÄdÄ«ts, ka atbildei uz jautÄjumu jÄbÅ«t jautÄjuma valodÄ.

Uzvednes teksts var bÅ«t daÅ¾ÄdÄs valodÄs. To var papildinÄt ar Ä«paÅ¡Äm, konkrÄ“tam klientam specifiskÄm norÄdÄ“m:

Tu esi uzÅ†Ä“muma "X" virtuÄlÄ darbiniece Y. LÅ«dzu, sniedz Ä«sas un latviski gramatiski korektas atbildes sievieÅ¡u dzimtÄ“. Izvairies no 2. personas lietojuma daudzskaitlÄ« un lieto darbÄ«bas vÄrdus otrÄs personas vienskaitlÄ«.

Atbildi draudzÄ«gi, reaÄ£Ä“jot ar neitrÄlÄm un Ä«sÄm atbildÄ“m uz elementÄrÄm saziÅ†as frÄzÄ“m Ärpus dotÄ konteksta. PiemÄ“ram, sasveicinoties (Uz sarunbiedra jautÄjumu 'Labdien' vai 'sveiki' - atbildi: 'Sveiki! KÄ varu jums palÄ«dzÄ“t?'), atsveicinoties (uz redzÄ“Å¡anos, atÄ), un atbildi neitrÄli, Ä«si uz ikdienas sarunvalodas frÄzÄ“m (piemÄ“ram, kÄ tu jÅ«ties, kÄ jums iet).

Atbildi uz jautÄjumiem par uzÅ†Ä“mumu un tÄ kontekstÄ, ja iespÄ“jams, sniedz piemÄ“rus un saites uz attÄ“liem, mÄjaslapÄm un video. RÄdi attÄ“lus.

LÅ«dzu, atbildi, izmantojot informÄciju, kas ir kontekstÄ vai Ä¼oti tuvu tam pÄ“c uzbÅ«ves un struktÅ«ras. Neizmanto valodas lÄ«dzekÄ¼us Ärpus konteksta, uzturi kontekstÄ izmantoto valodas struktÅ«ru un lÄ«dzekÄ¼us. ÄªpaÅ¡a uzmanÄ«ba jÄpievÄ“rÅ¡ vÄrdiem, kas norÄda uz laiku - Å¡odien, vakar, aizvakar, rÄ«t, parÄ«t - noteikt, kÄda nedÄ“Ä¼as diena atbilst tam, kas ir norÄdÄ«ts nÄkamajÄ teikumÄ, un Ä£enerÄ“ atbildes par vajadzÄ«go nedÄ“Ä¼as dienu. Ja kontekstÄ ir informÄcija, kurÄs dienÄs produkti ir pieejami, Å†em to vÄ“rÄ. Ja lietotÄjs jautÄ par ieveÅ¡anu, saproti to kÄ jautÄjumu par nodoÅ¡anu.

LÅ«dzu, sniedz Ä«sas un tieÅ¡as atbildes, koncentrÄ“joties tikai uz uzdotajiem jautÄjumiem. Ja jautÄjums ir par cenu, maksu vai ieveÅ¡anu un konkrÄ“tais produkts nav pieminÄ“ts kontekstÄ, atbildi, ka konteksts nesniedz atbildi.

* 1. JautÄjumu klasificÄ“Å¡anai izmantojamÄs uzvednes

Ja zinÄÅ¡anu bÄzÄ“ ir daudz daÅ¾Ädu failu par atÅ¡Ä·irÄ«gÄm tÄ“mÄm, lietderÄ«gi ir saÅ¡aurinÄt datu kopu, no kuras tiks izgÅ«ti jautÄjumam atbilstoÅ¡i konteksta fragmenti. To var izdarÄ«t, ar LLM palÄ«dzÄ«bu pieÅ¡Ä·irot lietotÄja jautÄjumam kÄdu no iepriekÅ¡ definÄ“tÄm kategorijÄm. Faili zinÄÅ¡anu bÄzÄ“ arÄ« tiek marÄ·Ä“ti ar Å¡Ä«m kategorijÄm, tÄdÄ“Ä¼ ir iespÄ“ja veikt filtrÄ“Å¡anu pirms jautÄjumam noderÄ«ga konteksta izguves. KlasificÄ“Å¡anas vairÄkpiemÄ“ru uzvednÄ“ ir pÄrskaitÄ«tas kategorijas, ir sniegti atslÄ“gvÄrdu piemÄ“ri, kuri liecina par jautÄjuma piederÄ«bu kategorijai, ir norÄdÄ«ts formÄts, kÄdÄ atgriezt atbildi, ir norÄdÄ«ti vairÄki piemÄ“ri ar jautÄjumiem un kÄdas kategorijas tiem pieÅ¡Ä·irt (â€œ{question}â€ tiek aizvietots ar lietotÄja jautÄjumu):

*You are an intelligent question classifier. Your task is to determine which category a user's question belongs to. The categories are:*

*1. BoilerMaintenance (examples: 'boiler', 'maintenance').*

*2. InsuranceServices (examples: 'insurance', 'payment safety').*

*3. ChimneyCleaning (examples: 'chimney', 'detector', 'cleaning').*

*4. OtherTopics (examples: 'dinamisk', 'stabil', 'invoice').*

*Your job is to analyze the question and respond in JSON format with the structure: `{"category": "<category>"}` Here `<category>` should be one of: 'BoilerMaintenance', 'InsuranceServices', 'ChimneyCleaning', or 'OtherTopics.'* 

*Examples: - Question: 'How does gas boiler maintenance work?' Answer: `{"category": "BoilerMaintenance"}`* 

*- Question: 'Is there insurance for chimney sweep services?' Answer: `{"category": "InsuranceServices"}`* 

*- Question: 'How do I clean a chimney?' Answer: `{"category": "ChimneyCleaning"}`* 

*- Question: 'What is the weather today?' Answer: `{"category": "OtherTopics"}`*

*User Question: "{question}"*

*Your Answer:*

* 1. Uzvedne kopsavilkuma Ä£enerÄ“Å¡anai

Lai Ä£enerÄ“tu faila kopsavilkumu, fails vispirms tiek sadalÄ«ts fragmentos. Tad katram fragmentam tiek Ä£enerÄ“ts kopsavilkums, izmantojot Å¡Ädu uzvedni (â€œ{chunk}â€ tiek aizvietots ar fragmenta tekstu):

*Here is the text fragment:*

*<fragment>*

*{chunk}*

*</fragment>*

*---------------------*

*Generate a concise summary for this text.*

PÄ“c tam fragmentu kopsavilkumi tiek sadalÄ«ti pa porcijÄm (fragmentu kopsavilkumu skaits vienÄ porcijÄ ir atkarÄ«gs no LLM konteksta loga izmÄ“ra) un katrai no porcijÄm tiek Ä£enerÄ“ts kopsavilkums, izmantojot Å¡o paÅ¡u uzvedni. Process iteratÄ«vi tiek atkÄrtots, lÄ«dz tiek iegÅ«ts viens kopÄ“js visa faila kopsavilkums. Å Äds algoritms nodroÅ¡ina to, ka informÄcija no katra faila fragmenta tiek atspoguÄ¼ota arÄ« kopÄ“jÄ faila kopsavilkumÄ.

* 1. Uzvednes tabulÄru datu izmantoÅ¡anai

TabulÄru datu izmantoÅ¡ana RAG risinÄjumÄ var radÄ«t grÅ«tÄ«bas, ja tabulas datu izmÄ“rs pÄrsniedz pieÄ¼aujamo LLM konteksta loga izmÄ“ru un visa tabula neietilpst vienÄ fragmentÄ. Ir vajadzÄ«ga atÅ¡Ä·irÄ«ga pieeja. TabulÄrus datus optimÄlÄk var izmantot, ja tie tiek iekÄ¼auti SQL datubÄzÄ“ un ar SQL vaicÄjuma palÄ«dzÄ«bu tiek izgÅ«tas lietotÄja jautÄjumam atbilstoÅ¡as datu rindas, ko var pievienot RAG uzvednei kÄ konteksta datus. Lai to Ä«stenotu, var izmantot papildu uzvedni, ar kuras palÄ«dzÄ«bu vispirms no lietotÄja jautÄjuma tiek Ä£enerÄ“ts SQL vaicÄjums (â€œ{schema}â€ tiek aizvietots ar tabulas shÄ“mu un â€œ{question}â€ tiek aizvietots ar lietotÄja jautÄjumu):

*SQL Database contains table whose schema we represent in the following JSON format. Table name is in "name" key, database type in "dbtype" key, and a list of field names and types in "fields" key. Some fields have restricted set of allowed values in "values" key.*

*Create the query to SQL Database for the user question, or return NONE if it is not possible to convert user question into query. The query must contain up to five fields related to user question. Use exactly the same field names as specified in the schema. include field in "" if it's name contains non-alphanumeric symbols.*

*For example, if you have table with the schema* 

*{'name': 'bernudarzi', 'fields': [{'name': 'name\_of\_educational\_institution', 'type': 'varchar'},{'name': 'address', 'type': 'varchar'},{'name': 'e-mail', 'type': 'varchar'},{'name': 'telephone', 'type': 'real'},{'name': 'manager', 'type': 'varchar'},{'name': 'language\_of\_study', 'type': 'varchar','values': ['latvieÅ¡u','krievu','poÄ¼u','franÄu']},{'name': 'number\_of\_children', 'type': 'bigint}]} and client asks "which institutions have more than hundred children", you must return the following SQL query: "SELECT name\_of\_educational\_institution, number\_of\_children FROM bernudarzi WHERE number\_of\_children > 100"*

*For the fields with restricted values use only thouse words that are in the schema. For example, for the question "cik bÄ“rnu ir poÄ¼u bÄ“rnudÄrzÄ" generate SQL query "SELECT name\_of\_educational\_institution, number\_of\_children FROM bernudarzi WHERE language\_of\_study='poÄ¼u'".*

*The answer must always contain a valid SQL query or NONE if it is not possible to create a query from the user's question. Do not explain your answer. If necessary generate several queries separated by ';'. Avoid using UNION operator. Use LIKE operator with wildcards to filter by the text fields. When location is asked use address field with LIKE operator and wildcards.*

*SQL Database table schema: {schema}*

*User question: {question}*

*SQL query:*

Å Ä« ir vairÄkpiemÄ“ru uzvedne, kurÄ dots tabulas shÄ“mas paraugs, vairÄki jautÄjumi un tiem atbilstoÅ¡i SQL vaicÄjumu paraugi, kÄ arÄ« ir norÄdÄ«ts, kÄdus SQL vaicÄjuma operatorus lietot vai nelietot.

PiedÄvÄtÄ algoritma darbÄ«ba tika pÄrbaudÄ«ta eksperimentÄli. PostgreSQL datubÄzÄ“ tika iekÄ¼auta tabula ar Latvijas pirmsskolas mÄcÄ«bu iestÄÅ¾u datiem (591 ieraksts). Tabulas lauki saturÄ“ja informÄciju par iestÄdes nosaukumu, adresi, reÄ£istrÄcijas numuru, vadÄ«tÄju, e-pasta adresi, telefona numuru, apmÄcÄ«bas valodu, izglÄ«tojamo skaitu. Tika izveidots saraksts ar 43 jautÄjumiem. Uz 40 jautÄjumiem ir iespÄ“jams pilnÄ«bÄ vai daÄ¼Ä“ji atbildÄ“t, izmantojot tabulas datus. 3 jautÄjumi ir nesaistÄ«ti ar tabulas datiem. JautÄjumi bija par izglÄ«tÄ«bas iestÄÅ¾u kontaktinformÄciju, cik bÄ“rnu ir kÄdÄ izglÄ«tÄ«bas iestÄdÄ“, kurÄ izglÄ«tÄ«bas iestÄdÄ“ ir vismazÄk vai visvairÄk bÄ“rnu, cik izglÄ«tÄ«bas iestÄÅ¾u ir kÄdÄ pilsÄ“tÄ, u.tml.

Izmantojot vairÄkpiemÄ“ru SQL vaicÄjuma uzvedni, ar OpenAI *gpt-35-turbo* un *gpt-4o* modeli tika Ä£enerÄ“ti jautÄjumiem atbilstoÅ¡i vaicÄjumi. Eksperiments tika atkÄrtos arÄ« ar bezpiemÄ“ru uzvedni (tÄ pati uzvedne, tikai izmesti abi jautÄjumu un tiem atbilstoÅ¡o vaicÄjumu piemÄ“ri). *gpt-35-turbo* modelis Ä£enerÄ“ja vaicÄjumus gandrÄ«z visiem jautÄjumiem, izÅ†emot 3 jautÄjumiem, kas nav saistÄ«ti ar tabulas datiem. PretstatÄ tam, *gpt-4o* modelis Ä£enerÄ“ja vaicÄjumus tikai tad, ja, izmantojot tabulas laukus, ir iespÄ“jams izgÅ«t jautÄjumam atbilstoÅ¡us datus. PiemÄ“ram, jautÄjumam â€œ*KurÄ pilsÄ“tÄ ir vairÄk bÄ“rnudÄrzu â€“ KuldÄ«gÄ vai JelgavÄ?â€* nav iespÄ“jams Ä£enerÄ“t vaicÄjumu, kas atgrieÅ¾ ierakstus, jo tabulÄ nav lauka â€˜PilsÄ“taâ€™, pÄ“c kura varÄ“tu grupÄ“t un skaitÄ«t ierakstus. PilsÄ“tas nosaukums ir daÄ¼a no adreses lauka. TaÄu *gpt-35-turbo* modelis Ä£enerÄ“ja Å¡Ädu vaicÄjumu, kuru izpildot, netiek atgriezts neviens ieraksts:

*SELECT address, COUNT(name\_of\_institution) FROM bernudarzi WHERE address LIKE '%KuldÄ«ga%' OR address LIKE '%Jelgava%' GROUP BY address*

AtÅ¡Ä·irÄ«gi rezultÄti tika iegÅ«ti, izmantojot vairÄkpiemÄ“ru un bezpiemÄ“ru uzvednes. JautÄjumam â€œ*Cik bÄ“rnu ir bÄ“rnudÄrzos, kas atrodas OgrÄ“?â€* Ar vairÄkpiemÄ“ru uzvedni tika Ä£enerÄ“ts vaicÄjums, kas atgrieÅ¾ sarakstu ar visiem Ogres bÄ“rnudÄrziem:

*SELECT [Name of educational institution], [Number of children] FROM bernudarzi WHERE [Address] LIKE '%Ogre%'*

Ar bezpiemÄ“ra uzvedni tika Ä£enerÄ“ts vaicÄjums, kas atgrieÅ¾ bÄ“rnu skaitu Ogres bÄ“rnudÄrzos:

*SELECT SUM(number\_of\_children) FROM bernudarzi WHERE address LIKE '%Ogre%'*

Abi vaicÄjumi tika Ä£enerÄ“ti ar *gpt-4o*. Ar bezpiemÄ“ru uzvedÅ†u Ä£enerÄ“tu vaicÄjumu atbilde uz jautÄjumu tiek iegÅ«ta uzreiz. Pat ja ar vairÄkpiemÄ“ru uzvedni uzreiz atbilde netiek iegÅ«ta, iekÄ¼aujot ierakstus par visiem Ogres bÄ“rnudÄrziem RAG uzvednes konteksta sadaÄ¼Ä un Ä£enerÄ“jot atbildi ar LLM, modelim ir pietiekami daudz informÄcijas, lai aprÄ“Ä·inÄtu vajadzÄ«go informÄciju.

Eksperimentu rezultÄti liecina, ka LLM spÄ“j labi Ä£enerÄ“t SQL vaicÄjumus un piedÄvÄtÄ metode ir piemÄ“rota lielu tabulÄru datu izmantoÅ¡anai RAG risinÄjumos. TaÄu ir daÅ¾i ierobeÅ¾ojumi. InformÄcijai, par kuru lietotÄjs gribÄ“tu uzzinÄt kÄdus statistiskus datus (piemÄ“ram, skaitu, salÄ«dzinÄt mazÄk vai vairÄk, aprÄ“Ä·inÄt vidÄ“jo lielumu), ir jÄbÅ«t laukos, pÄ“c kuriem var grupÄ“t. PiemÄ“ros pilsÄ“tas vÄrds nebija atseviÅ¡Ä·Ä laukÄ. TurklÄt jÄÅ†em vÄ“rÄ, ka brÄ«vi uzdotÄ jautÄjumÄ lietotÄjs Ä«paÅ¡vÄrdus var lietot kÄdÄ locÄ«juma formÄ, kura var nesakrist ar Ä«paÅ¡vÄrda formu tabulÄrajos datos.

1. Eksperimentos izmantotie lielie valodas modeÄ¼i

Daudzu lielo valodas modeÄ¼u izveidÄ“ ir izmantota tÄ pati *Transformer* arhitektÅ«ra ar paÅ¡kontroles mehÄnismu. AtÅ¡Ä·irÄ«bas ir apmÄcÄ«bas datu daudzumÄ, izmantoto parametru skaitÄ vai vektortelpu izmantojumÄ. *Hugging Face* platformÄ ir pieejami vairÄk nekÄ 13 000 modeÄ¼i, kas ir izmantojami daÅ¾ÄdÄs jomÄs un ir piemÄ“roti daÅ¾ÄdÄm valodÄm. Neraugoties uz Å¡o daudzveidÄ«bu, mazÄk atbalstÄ«tajÄm valodÄm piemÄ“rotu modeÄ¼u skaits nav liels.

Eksperimentiem esam izvÄ“lÄ“juÅ¡ies populÄrÄkos modeÄ¼us, kuri bÅ«tu piemÄ“roti arÄ« valodÄm, kurÄs ir mazÄk resursu, t.i., latvieÅ¡u un lietuvieÅ¡u valodai. MÄ“s salÄ«dzinÄm gan komerciÄlos OpenAI modeÄ¼us, gan brÄ«vpieejas modeÄ¼us (sk. 2. tabulu). BrÄ«vpieejas modeÄ¼i tiek darbinÄti caur lokÄli uzstÄdÄ«tu *Ollama*[[1]](#footnote-2) platformu, kas nodroÅ¡ina datu privÄtumu.

2. tabula. Eksperimentos izmantotie daudzvalodu valodas modeÄ¼i (ar parametru skaitu miljardos iekavÄs)

| **Kategorija** | **GPT modeÄ¼i** | **Llama modeÄ¼i** | **Mistral modeÄ¼i** | **Gemma modeÄ¼i** | **Phi modeÄ¼i** |
| --- | --- | --- | --- | --- | --- |
| Autors | OpenAI | Meta | Mistral AI | Google | Microsoft |
| TestÄ“tie modeÄ¼i (parametri) | GPT-3.5.turbo-0125 (175b), GPT-4-0613, GPT-4o-2024-05-13 | Llama3 (8.03b), Llama3:70b (70.6b), Llama3.1 (8.03b), Llama3.1:70b (70.6b), Llama3.2 (3.21b) | Mistral-nemo:12b (12.2b) | Gemma2 (9.24b), Gemma2:27b (27.2b) | Phi3:3.8b (3.8b), Phi3:14b (14.0b) |

Papildus daudzvalodu modeÄ¼iem ir pÄrbaudÄ«ti arÄ« divi vienvalodas lietuvieÅ¡u valodas modeÄ¼i ***Lt-Llama2-7b-instruct****[[2]](#footnote-3)*un ***Lt-Llama2-13b-instruct****[[3]](#footnote-4)*. Tie ir apmÄcÄ«ti, izmantojot *Llama2* neironu tÄ«kla arhitektÅ«ru, un ir paredzÄ“ti jautÄjumu atbildÄ“Å¡anas uzdevumam.

1. Teksta tulkoÅ¡ana ar lielo valodas modeÄ¼u palÄ«dzÄ«bu

MaÅ¡Ä«ntulkoÅ¡ana dabiskÄs valodas apstrÄdÄ“ ir uzdevums, kas fokusÄ“jas uz teksta automÄtisku pÄrveidi no vienas valodas citÄ. MaÅ¡Ä«ntulkoÅ¡anas eksperimentiem tiek izmantota FLORES-200[[4]](#footnote-5) datu kopa, kurÄ ir ietverti paralÄ“li teikumi vairÄk nekÄ 200 valodÄs. MÄ“s izmantojam angÄ¼u valodu kÄ avota vai mÄ“rÄ·a valodu, tulkojot no vai uz latvieÅ¡u vai lietuvieÅ¡u valodu. Tiek sagaidÄ«ts, ka rezultÄti latvieÅ¡u un lietuvieÅ¡u valodai bÅ«s lÄ«dzÄ«gi, jo abas valodas pieder vienai baltu valodu grupai. SalÄ«dzinÄÅ¡anai mÄ“s eksperimentos esam iekÄ¼ÄvuÅ¡i igauÅ†u valodu no somugru valodu grupas un Äehu valodu, kas pieder slÄvu valodu grupai. MÄ“s izmantojam *devtest* daÄ¼u no FLORES-200 datu kopas. TajÄ ir 1012 paralÄ“li teikumi.

Visos tulkoÅ¡anas uzdevumos tiek izmantota Å¡Äda vienkÄrÅ¡a uzvedne angÄ¼u valodÄ (â€œ{text}â€ tiek aizvietots ar tulkojamo tekstu avotvalodÄ, â€œ{lang\_a}â€ tiek aizvietots ar avotvalodu un â€œ{lang\_b}â€ tiek aizvietots ar mÄ“rÄ·valodu):

{text}

Translate the above {lang\_a} text into {lang\_b}

RezultÄtu vÄ“rtÄ“Å¡anai tiek izmantotas Äetras metrikas:

* **BLEU** ir maÅ¡Ä«ntulkoÅ¡anÄ plaÅ¡i izmantota metrika. TÄ ir Ätri un viegli aprÄ“Ä·inÄma un labi darbojas valodÄm ar lÄ«dzÄ«gu vÄrdu secÄ«bu. Å Ä«s metodes trÅ«kums ir pÄrmÄ“rÄ«ga paÄ¼auÅ¡anÄs uz n-grammu pÄrklÄjumu, ignorÄ“jot izteikuma jÄ“gu. TÄ slikti darbojas, vÄ“rtÄ“jot morfoloÄ£iski bagÄtas valodas, jo pat neliela vÄrdu kÄrtÄ«bas maiÅ†a var bÅ«tiski ietekmÄ“t vÄ“rtÄ“jumu, pat, ja tulkojums ir pareizs.
* **ChrF** metrika ir balstÄ«ta uz simbolu lÄ«meÅ†a precizitÄti un pÄrklÄjumu. TÄdÄ“Ä¼ tÄ ir vairÄk piemÄ“rota morfoloÄ£iski bagÄtÄm valodÄm. TÄs stiprÄ puse ir labÄka vÄrdu locÄ«jumu formu vÄ“rtÄ“Å¡ana salÄ«dzinÄjumÄ ar BLEU. TomÄ“r ir arÄ« trÅ«kumi. Å Ä«s metrikas rezultÄtus ir grÅ«ti skaidrot, simbolu lÄ«meÅ†a vÄ“rtÄ“jums daÅ¾kÄrt var pieÅ¡Ä·irt lielÄku svaru lÄ«dzÄ«gi rakstÄmiem, bet pÄ“c nozÄ«mes nesaistÄ«tiem vÄrdiem.
* **TER** metrika vÄ“rtÄ“ darbÄ«bu skaitu (teksta iesprauÅ¡ana, izmeÅ¡ana, maiÅ†a, pÄrvietoÅ¡ana), kas nepiecieÅ¡amas, lai maÅ¡Ä«ntulkotu tekstu pÄrveidotu references tulkojumÄ. TÄ ir labi interpretÄ“jama, Ä«paÅ¡i vÄ“rtÄ“jot pÄ“crediÄ£Ä“Å¡anas scenÄrijus, jo atspoguÄ¼o, cik daudz pÅ«Ä¼u nepiecieÅ¡ams, lai labotu tulkojumu. TÄs trÅ«kumi ietver jutÄ«bas trÅ«kumu pret sinonÄ«miju un teksta plÅ«dumu. Tas nozÄ«mÄ“, ka tulkojums ar nedaudz atÅ¡Ä·irÄ«gu, bet pareizu izteikumu joprojÄm var saÅ†emt sliktu vÄ“rtÄ“jumu.
* **COMET** ir moderna vÄ“rtÄ“Å¡anas metrika, kas izmanto ar cilvÄ“ka vÄ“rtÄ“juma datiem apmÄcÄ«tus neironu tÄ«kla modeÄ¼us. TÄ spÄ“j uztvert ne tikai vienkÄrÅ¡u vÄrdu sakritÄ«bu, bet arÄ« teksta semantisko nozÄ«mi, padarot to tuvÄku cilvÄ“ka vÄ“rtÄ“jumam. TÄ ir piemÄ“rota tulkojumu vÄ“rtÄ“Å¡anai starp daÅ¾Ädiem valodu pÄriem. SkaitÄ¼oÅ¡anas ziÅ†Ä COMET metrika ir dÄrga salÄ«dzinÄjumÄ ar tradicionÄlajÄm metrikÄm. Ir vajadzÄ«gs iepriekÅ¡ apmÄcÄ«ts modelis. Å Ä«s metrikas rezultÄtus nav iespÄ“jams interpretÄ“t salÄ«dzinÄjumÄ ar BLEU vai TER metrikÄm. TÄpÄ“c to nevar izmantot, ja nepiecieÅ¡ams saprast, cik kvalitatÄ«va ir konkrÄ“ta sistÄ“ma, tomÄ“r tÄ ir piemÄ“rota, lai salÄ«dzinÄtu divas daÅ¾Ädas maÅ¡Ä«ntulkoÅ¡anas sistÄ“mas, un secinÄtu, kura sistÄ“ma Ä¼auj iegÅ«t labÄkus tulkojumus.

MaÅ¡Ä«ntulkoÅ¡anas eksperimenti tika veikti, salÄ«dzinot standartizÄ“tus tulkojumus, kuros pieturzÄ«mes, tukÅ¡umzÄ«mes, pÄ“diÅ†as, iekavas un citi simboli aizstÄti ar atbilstoÅ¡iem simboliem no ASCII tabulas. TabulÄs atspoguÄ¼oti rezultÄti, vÄ“rtÄ“jot ar BLEU (sk. 3. tabulu), ChrF (sk. 4. tabulu), TER (sk. 5. tabulu) un COMET (sk. 6. tabulu) metrikÄm.

3. tabula. BLEU rezultÄti tulkojumiem ar daÅ¾Ädiem LLM

| **TulkoÅ¡anas virziens** | **gpt-3.5-turbo-0125** | **gpt-4o-2024-05-13** | **llama3** | **llama3:70b** | **llama3.1** | **llama3.1:70b** | **llama3.2** | **gemma2** | **gemma2:27b** | **mistral-nemo:12b** | **phi3:3.8b** | **phi3:14b** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| enğŸ¡ªcs | 32.37 | 37.12 | 19.01 | 28.49 | 17.92 | 28.44 | 13.69 | 25.13 | 30.12 | 19.82 | 0.25 | 7.78 |
| enğŸ¡ªet | 26.59 | 31.69 | 9.11 | 19.19 | 6.68 | 17.91 | 4.97 | 16.00 | 20.21 | 11.35 | 0.13 | 1.98 |
| enğŸ¡ªlt | 23.55 | 30.83 | 8.36 | 17.47 | 7.86 | 18.07 | 4.49 | 17.83 | 22.52 | 10.69 | 0.02 | 0.87 |
| enğŸ¡ªlv | 25.89 | 35.58 | 8.76 | 19.29 | 6.89 | 19.32 | 3.94 | 17.87 | 24.11 | 11.74 | 0.01 | 0.02 |
| csğŸ¡ªen | 40.58 | 42.42 | 32.67 | 38.10 | 30.42 | 35.13 | 31.15 | 39.48 | 40.56 | 32.18 | 0.00 | 0.06 |
| etğŸ¡ªen | 38.08 | 40.28 | 18.75 | 26.48 | 18.22 | 23.06 | 16.56 | 33.68 | 37.01 | 24.71 | 0.00 | 0.04 |
| ltğŸ¡ªen | 32.99 | 36.37 | 19.17 | 24.67 | 17.94 | 23.76 | 16.66 | 32.92 | 33.65 | 23.41 | 0.00 | 0.04 |
| lvğŸ¡ªen | 34.23 | 37.76 | 18.05 | 25.83 | 18.41 | 25.56 | 17.20 | 33.61 | 35.51 | 25.45 | 0.00 | 0.06 |

4. tabula. ChrF rezultÄti tulkojumiem ar daÅ¾Ädiem LLM

| **TulkoÅ¡anas virziens** | **gpt-3.5-turbo-0125** | **gpt-4o-2024-05-13** | **llama3** | **llama3:70b** | **llama3.1** | **llama3.1:70b** | **llama3.2** | **gemma2** | **gemma2:27b** | **mistral-nemo:12b** | **phi3:3.8b** | **phi3:14b** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| enğŸ¡ªcs | 56.89 | 60.26 | 45.80 | 53.83 | 44.11 | 53.59 | 38.35 | 50.78 | 54.94 | 45.66 | 6.81 | 31.06 |
| enğŸ¡ªet | 56.53 | 59.72 | 36.85 | 49.56 | 33.56 | 48.65 | 28.2 | 46.08 | 50.75 | 39.86 | 7.87 | 22.18 |
| enğŸ¡ªlt | 52.22 | 58.18 | 35.90 | 47.08 | 34.46 | 47.73 | 27.92 | 46.71 | 51.43 | 38.62 | 6.84 | 15.50 |
| enğŸ¡ªlv | 54.08 | 60.78 | 35.43 | 48.11 | 32.19 | 48.58 | 26.27 | 46.65 | 52.3 | 39.35 | 5.94 | 7.75 |
| csğŸ¡ªen | 65.14 | 66.56 | 58.64 | 62.91 | 56.66 | 60.60 | 57.25 | 63.84 | 64.51 | 58.14 | 4.11 | 6.38 |
| etğŸ¡ªen | 63.10 | 64.82 | 45.42 | 52.34 | 43.74 | 49.09 | 42.05 | 59.10 | 61.91 | 51.60 | 3.62 | 7.05 |
| ltğŸ¡ªen | 58.18 | 61.05 | 44.81 | 50.05 | 43.28 | 49.41 | 42.38 | 57.80 | 58.41 | 49.28 | 3.51 | 7.51 |
| lvğŸ¡ªen | 60.94 | 63.83 | 45.28 | 52.33 | 44.39 | 51.34 | 43.92 | 59.03 | 60.71 | 52.23 | 3.30 | 7.16 |

5. tabula. TER rezultÄti tulkojumiem ar daÅ¾Ädiem LLM

| **TulkoÅ¡anas virziens** | **gpt-3.5-turbo-0125** | **gpt-4o-2024-05-13** | **llama3** | **llama3:70b** | **llama3.1** | **llama3.1:70b** | **llama3.2** | **gemma2** | **gemma2:27b** | **mistral-nemo:12b** | **phi3:3.8b** | **phi3:14b** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| enğŸ¡ªcs | 55.02 | 51.03 | 69.53 | 59.16 | 73.46 | 59.75 | 78.18 | 62.92 | 57.37 | 68.69 | 117.55 | 89.47 |
| enğŸ¡ªet | 61.54 | 57.45 | 85.84 | 70.65 | 98.47 | 72.79 | 97.37 | 73.45 | 67.65 | 81.02 | 127.14 | 107.35 |
| enğŸ¡ªlt | 66.66 | 59.75 | 86.16 | 73.52 | 94.68 | 73.73 | 97.39 | 73.23 | 66.95 | 82.83 | 122.59 | 169.91 |
| enğŸ¡ªlv | 62.07 | 54.16 | 83.84 | 69.35 | 92.97 | 70.13 | 96.24 | 70.48 | 63.08 | 79.37 | 115.73 | 185.80 |
| csğŸ¡ªen | 45.88 | 44.07 | 54.22 | 48.27 | 55.55 | 51.23 | 55.28 | 46.31 | 45.43 | 54.08 | 101.09 | 127.72 |
| etğŸ¡ªen | 48.43 | 46.61 | 75.17 | 62.91 | 74.27 | 68.89 | 76.66 | 52.31 | 49.05 | 63.04 | 101.66 | 129.60 |
| ltğŸ¡ªen | 55.27 | 51.95 | 73.14 | 64.70 | 73.46 | 66.40 | 75.14 | 54.33 | 53.47 | 65.73 | 101.51 | 133.21 |
| lvğŸ¡ªen | 52.94 | 49.29 | 74.88 | 62.69 | 74.74 | 64.37 | 73.8 | 53.59 | 51.61 | 62.50 | 100.51 | 126.13 |

6. tabula. COMET rezultÄti tulkojumiem ar daÅ¾Ädiem LLM

| **TulkoÅ¡anas virziens** | **gpt-3.5-turbo-0125** | **gpt-4o-2024-05-13** | **llama3** | **llama3:70b** | **llama3.1** | **llama3.1:70b** | **llama3.2** | **gemma2** | **gemma2:27b** | **mistral-nemo:12b** | **phi3:3.8b** | **phi3:14b** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| enğŸ¡ªcs | 0.91 | 0.92 | 0.81 | 0.90 | 0.82 | 0.90 | 0.66 | 0.89 | 0.91 | 0.84 | 0.25 | 0.51 |
| enğŸ¡ªet | 0.92 | 0.92 | 0.65 | 0.86 | 0.63 | 0.87 | 0.48 | 0.84 | 0.89 | 0.75 | 0.27 | 0.37 |
| enğŸ¡ªlt | 0.88 | 0.91 | 0.62 | 0.83 | 0.61 | 0.84 | 0.46 | 0.86 | 0.89 | 0.73 | 0.26 | 0.32 |
| enğŸ¡ªlv | 0.88 | 0.91 | 0.59 | 0.82 | 0.58 | 0.83 | 0.44 | 0.83 | 0.88 | 0.72 | 0.25 | 0.27 |
| csğŸ¡ªen | 0.89 | 0.89 | 0.86 | 0.88 | 0.86 | 0.87 | 0.86 | 0.89 | 0.89 | 0.87 | 0.32 | 0.33 |
| etğŸ¡ªen | 0.90 | 0.90 | 0.78 | 0.83 | 0.79 | 0.82 | 0.76 | 0.88 | 0.89 | 0.85 | 0.33 | 0.34 |
| ltğŸ¡ªen | 0.86 | 0.88 | 0.77 | 0.81 | 0.77 | 0.82 | 0.75 | 0.87 | 0.87 | 0.82 | 0.32 | 0.34 |
| lvğŸ¡ªen | 0.87 | 0.89 | 0.77 | 0.83 | 0.78 | 0.82 | 0.76 | 0.87 | 0.88 | 0.84 | 0.33 | 0.34 |

*GPT-4o* modelis uzrÄda labÄkos rezultÄtus visiem tulkoÅ¡anas virzieniem. NÄkamÄ vietÄ var ierindot GPT*-3.5-turbo* vai *Gemma2:27b* modeli. ModeÄ¼i ar lielÄku parametru skaitu (*Llama3:70b*, *Llama3.1:70b*, *Gemma2:27b*, un *Phi3:14b*) parasti uzrÄda labÄkus rezultÄtus par tÄ paÅ¡a tipa mazÄkiem modeÄ¼iem (*Llama3*, *Llama3.1*, *Gemma2*, un *Phi3.8*). Parametru skaits ir skatÄms 2. tabulÄ. Tas, iespÄ“jams, saistÄ«ts ar to, ka lielÄki modeÄ¼i labÄk spÄ“j saprast un apstrÄdÄt sareÅ¾Ä£Ä«tÄkas valodas konstrukcijas. VÄ“rtÄ“jums tulkojumiem, kas iegÅ«ti ar *Phi* modeÄ¼iem, liecina par Å¡o modeÄ¼u nepiemÄ“rotÄ«bu lietuvieÅ¡u, latvieÅ¡u, igauÅ†u un Äehu valodai.

LLM modeÄ¼u spÄ“ja tulkot tika salÄ«dzinÄta ar *DeepL*, kas ir neironu maÅ¡Ä«ntulkoÅ¡anas sistÄ“ma, ko veidojis VÄcijas uzÅ†Ä“mums DeepL GmbH. *DeepL* nereti pÄrspÄ“j citas maÅ¡Ä«ntulkoÅ¡anas sistÄ“mas, piemÄ“ram, *Google Translate* un *Microsoft Translator*, Ä«paÅ¡i valodas plÅ«stamÄ«bas un dabiskuma ziÅ†Ä. *DeepL* izmanto dziÄ¼Äs mÄcÄ«Å¡anÄs metodes un lielu neironu tÄ«klu, kas ir apmÄcÄ«ts ar daudzvalodu datiem. *DeepL* salÄ«dzinÄjumÄ ar *GPT-4o* uzrÄda labÄkus rezultÄtus, ja tiek tulkots no morfoloÄ£iski vienkÄrÅ¡ÄkÄm valodÄm uz morfoloÄ£iski bagÄtÄkÄm valodÄm (sk. 7. tabulu). SavukÄrt tulkojot no morfoloÄ£iski bagÄtÄkÄm valodÄm, *GPT-4o* ir vienÄdi vai labÄki rezultÄti. AtÅ¡Ä·irÄ«ba rezultÄtos gan ir minimÄla. JÄatzÄ«mÄ“, ka *GPT-4o* nav Ä«paÅ¡i apmÄcÄ«ts maÅ¡Ä«ntulkoÅ¡anas uzdevumam.

7. tabula. COMET rezultÄtu salÄ«dzinÄjums, tulkojot ar DeepL un GPT-4o

| **TulkoÅ¡anas virziens** | **GPT-4o** | **DeepL** | **LabÄki rezultÄti** |
| --- | --- | --- | --- |
| enğŸ¡ªcs | 0.92 | 0.93 | deepL |
| enğŸ¡ªet | 0.92 | 0.93 | deepL |
| enğŸ¡ªlt | 0.91 | 0.92 | deepL |
| enğŸ¡ªlv | 0.91 | 0.92 | deepL |
| csğŸ¡ªen | 0.89 | 0.89 | - |
| etğŸ¡ªen | 0.90 | 0.90 | - |
| ltğŸ¡ªen | 0.88 | 0.87 | gpt-4 |
| lvğŸ¡ªen | 0.89 | 0.89 | - |

Visi iepriekÅ¡Ä“jie eksperimenti ar ne-GPT modeÄ¼iem tika veikti ar kvantÄ“tajÄm (4-bitu) versijÄm. Å Ädi modeÄ¼i ir mazÄki izmÄ“ru ziÅ†Ä un efektÄ«vÄki, tÄdÄ“Ä¼ tos var darbinÄt uz iekÄrtÄm ar ierobeÅ¾otu resursu pieejamÄ«bu. TomÄ“r 4-bitu kvantÄ“Å¡ana bieÅ¾i vien tiek uzskatÄ«ta par pÄrÄk agresÄ«vu, Ä«paÅ¡i uzdevumiem, kuriem ir svarÄ«ga augsta rezultÄtu precizitÄte. RezultÄti, tulkojot ar nekvantÄ“tiem (16-bitu) modeÄ¼iem, ir skatÄmi 8. tabulÄ.

8. tabula. COMET rezultÄti, tulkojot ar nekvantÄ“tiem modeÄ¼iem (salÄ«dzinÄjumÄ ar GPT-4o)

| **TulkoÅ¡anas virziens** | **GPT-4o** | **Llama3.1** | **Llama3.1:8b-instruct-fp16** | **Llama3.1:70b** | **Llama3.2** | **Llama3.2:3b-instruct-fp16** | **gemma2** | **gemma2:9b-instruct-fp16** | **gemma2:27b** | **Gemma2:27b-instruct-fp16** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| enğŸ¡ªcs | 0.92 | 0.82 | 0.86 | 0.90 | 0.66 | 0.68 | 0.89 | 0.90 | 0.91 | 0.91 |
| enğŸ¡ªet | 0.92 | 0.63 | 0.74 | 0.87 | 0.48 | 0.50 | 0.84 | 0.86 | 0.89 | 0.89 |
| enğŸ¡ªlt | 0.91 | 0.61 | 0.71 | 0.84 | 0.46 | 0.48 | 0.86 | 0.87 | 0.89 | 0.89 |
| enğŸ¡ªlv | 0.91 | 0.58 | 0.69 | 0.83 | 0.44 | 0.46 | 0.83 | 0.84 | 0.88 | 0.89 |
| csğŸ¡ªen | 0.89 | 0.86 | 0.88 | 0.87 | 0.86 | 0.86 | 0.89 | 0.89 | 0.89 | 0.89 |
| etğŸ¡ªen | 0.90 | 0.79 | 0.86 | 0.82 | 0.76 | 0.77 | 0.88 | 0.88 | 0.89 | 0.89 |
| ltğŸ¡ªen | 0.88 | 0.77 | 0.84 | 0.82 | 0.75 | 0.76 | 0.87 | 0.87 | 0.87 | 0.87 |
| lvğŸ¡ªen | 0.89 | 0.78 | 0.85 | 0.82 | 0.76 | 0.78 | 0.87 | 0.87 | 0.88 | 0.88 |

NekvantÄ“tie modeÄ¼i sasniedz augstÄku precizitÄti nekÄ to kvantÄ“tÄs versijas. TomÄ“r neviens no tiem nepÄrspÄ“j *GPT-4o* visiem valodu pÄriem. VeiktspÄ“jas atÅ¡Ä·irÄ«bas starp nekvantÄ“tajiem modeÄ¼iem, piemÄ“ram, *Gemma2:27B* un *Llama3.1:70B*, salÄ«dzinÄjumÄ ar *GPT-4o* ir vÄ“l mazÄkas. Tas apstiprina iepriekÅ¡ konstatÄ“to, ka arÄ« ne-GPT modeÄ¼i var bÅ«t efektÄ«vi tulkoÅ¡anas uzdevumos valodÄm, kurÄm pieejamo datu apjoms LLM apmÄcÄ«bai ir salÄ«dzinoÅ¡i mazs.

1. KontekstÄ balstÄ«tu atbilÅ¾u Ä£enerÄ“Å¡ana daÅ¾ÄdÄs valodÄs

Turpinot 1. aktivitÄtÄ“ pÄ“tÄ«tÄs metodes, kas saistÄ«tas ar jautÄjumam atbilstoÅ¡a konteksta izguvi, Å¡ajÄ aktivitÄtÄ“ mÄ“s padziÄ¼inÄti pÄ“tÄm RAG procesa otro daÄ¼u â€“ atbildes Ä£enerÄ“Å¡anu, balstoties uz konteksta informÄciju, kas ir iekÄ¼auta uzvednÄ“.

Å im mÄ“rÄ·im mÄ“s izmantojam daÄ¼u no [*rag-mini-wikipedia*](https://huggingface.co/datasets/rag-datasets/rag-mini-wikipedia) datu kopas. DaÄ¼Ä, ko mÄ“s izmantojam, ir iekÄ¼auti 60 VikipÄ“dijas rakstu teksti un 794 unikÄli jautÄjumi angÄ¼u valodÄ, kÄ arÄ« Ä«sas atbildes uz Å¡iem jautÄjumiem un norÄde uz failu, kurÄ atbilde ir atrodama. Å ai datu kopai esam veikuÅ¡i Å¡Ädus papildinÄjumus:

1. failu teksts ir sadalÄ«ts fragmentos, fragmentiem ir Ä£enerÄ“ti vektori un ievietoti TypeSense vektoru datubÄzÄ“ (vektori Ä£enerÄ“ti ar Hugging Face *paraphrase-multilingual-mpnet-base-v2* modeli);
2. ar OpenAI *GPT-4o* modeli ir identificÄ“ti faila fragmenti, kuros tieÅ¡i atbilde ir atrodama (oriÄ£inÄlajÄ marÄ·Ä“jumÄ jautÄjumam ir piekÄrtots viss fails);
3. ar OpenAI *GPT-4o* modeli references atbildes ir izvÄ“rstas lÄ«dz pilnam teikumam;
4. ar OpenAI *GPT-4o* modeli jautÄjumi un izvÄ“rstÄs references atbildes ir pÄrtulkotas latvieÅ¡u, lietuvieÅ¡u un igauÅ†u valodÄs.

JautÄjumam atbilstoÅ¡u failu fragmenti ir identificÄ“ti, izmantojot Å¡Ädu uzvedni (â€œ{n}â€ tiek aizvietots ar fragmentu skaitu failÄ un â€œ{chunklist}â€ tiek aizvietots ar fragmentu masÄ«vu):

Given a question and a list of text chunks, score the content of the chunks in 0 to 2 range.

0 - if chunk does not contain answer to the question,

1 - if chunk partly helps to answer the question,

2 - if chunk is highly relevant and holds answer to the question.

Do not repeat the text of the chunk, return only the list with numeric scores.

Here is the list of {n} text chunks:

{chunklist}

Here is the question:

LLM marÄ·Ä“jums nav pilnÄ«bÄ korekts. PÄrmarÄ·Ä“jot manuÄli 100 jautÄjumus, tika konstatÄ“tas 5 kÄ¼Å«das. VisÄ datu kopÄ bija arÄ« tÄdi jautÄjumi, kuriem LLM nebija varÄ“jis atrast atbilstoÅ¡us fragmentus, t.i., visi faila fragmenti bija marÄ·Ä“ti kÄ â€˜*0*â€™. Å Ädi jautÄjumi tika manuÄli laboti. Bija arÄ« neskaidri gadÄ«jumi. Ir tÄdi jautÄjumi, uz kuriem nav skaidras atbildes failÄ, taÄu tie ir izsecinÄmi. PiemÄ“ram, uz jautÄjumu â€œ*Vai Alesandro Volta bija Ä·Ä«mijas profesors?*â€ references atbilde ir noliedzoÅ¡a. JautÄjumam atbilstoÅ¡ajÄ failÄ nekas nav teikts par to, ka Volta nebija Ä·Ä«mijas profesors, bet ir informÄcija, ka viÅ†Å¡ bija fizikas profesors. Å ÄdÄm izsecinÄmÄm atbildÄ“m tika ieviests jauns marÄ·Ä“jums â€˜*3*â€™. KopumÄ marÄ·Ä“jums ir manuÄli mainÄ«ts 216 jautÄjumiem.

References atbildes ir izvÄ“rstas, izmantojot Å¡Ädu uzvedni (â€œ{q}â€ tiek aizvietots ar jautÄjumu un â€œ{a}â€ tiek aizvietots ar Ä«su references atbildi):

Given the question and the short answer, expand the answer into a full sentence

Here is the question: {q}

Here is the short answer: {a}

JautÄjumi un izvÄ“rstÄs references atbildes tiek tulkotas, izmantojot Å¡Ädu sistÄ“mas uzvedni (tulkojamais teksts tiek padots lielajam valodas modelim, izmantojot lietotÄja uzvedni; tÄ satur tikai tulkojamo tekstu; lÄ«dzÄ«gi ir arÄ« lietuvieÅ¡u un igauÅ†u valodai):

Translate sentence into Latvian. Return just translated text without any explanation.

PapildinÄtajÄ datu kopÄ ir Å¡Äda informÄcija â€“ fails, jautÄjums, Ä«sÄ references atbilde, izvÄ“rstÄ references atbilde, jautÄjumam atbilstoÅ¡i fragmenti, jautÄjums latviski, izvÄ“rstÄ references atbilde latviski, jautÄjums lietuviski, izvÄ“rstÄ references atbilde lietuviski, jautÄjums igauniski, izvÄ“rstÄ references atbilde igauniski (piemÄ“ru sk. 9. tabulÄ). PiemÄ“rÄ faila teksts ir dalÄ«ts astoÅ†os fragmentos, no kuriem pirmais fragments ir marÄ·Ä“ts kÄ atbildi saturoÅ¡s, bet nÄkamie pieci fragmenti kÄ saistÄ«ti ar jautÄjumu.

9. tabula. PapildinÄtÄs *wiki* datu kopas ieraksta paraugs

| **Lauks** | **VÄ“rtÄ«ba** |
| --- | --- |
| fails | S10\_set3\_a4 |
| jautÄjums | Is Antwerp a city? |
| Ä«sÄ references atbilde | Yes |
| izvÄ“rstÄ references atbilde | Yes, Antwerp is a city. |
| jautÄjumam atbilstoÅ¡i fragmenti | [2, 1, 1, 1, 1, 1, 0, 0] |
| jautÄjums latviski | Vai Antverpene ir pilsÄ“ta? |
| izvÄ“rstÄ references atbilde latviski | JÄ, Antverpene ir pilsÄ“ta. |
| jautÄjums lietuviski | Ar Antverpenas yra miestas? |
| izvÄ“rstÄ references atbilde lietuviski | Taip, Antverpenas yra miestas. |
| jautÄjums igauniski | Kas Antwerpen on linn? |
| izvÄ“rstÄ references atbilde igauniski | Jah, Antwerpen on linn. |

LiteratÅ«rÄ ir minÄ“ts, ka RAG risinÄjumu vÄ“rtÄ“Å¡anai var izmantot vairÄkas metrikas, kas balstÄ«tas gan uz tradicionÄlajÄm dabiskÄs valodas apstrÄdÄ“ lietotajÄm metrikÄm, piemÄ“ram, BLEU, ROUGE, F1, gan uz metrikÄm, kuras izmanto LLM. RAGEval (Zhou et al. 2024) izmanto tÄdas metrikas kÄ *completeness* â€˜pilnÄ«gumsâ€™, *hallucination* â€˜halucinÄ“Å¡anaâ€™, *irrelevancy* â€˜nesaistÄ«tÄ«baâ€™, kuras tiek aprÄ“Ä·inÄtas, vispirms no references atbildes ar LLM izgÅ«stot faktus un tad pÄrbaudot Å¡o faktu esamÄ«bu vai pretrunÄ«bu Ä£enerÄ“tajÄ atbildÄ“. Python bibliotÄ“kÄ *Ragas* (Es et al. 2023) ietvertas gan tradicionÄlÄs metrikas, gan LLM balstÄ«tas metrikas. Metrika *faithfulness* â€˜patiesumsâ€™ identificÄ“ faktus RAG risinÄjuma Ä£enerÄ“tajÄ atbildÄ“ un pÄrbauda, vai Å¡ie fakti ir izsecinÄmi no konteksta. Metrikas *response relevancy* â€˜atbildes atbilstÄ«baâ€™ aprÄ“Ä·inam ar LLM tiek Ä£enerÄ“ti RAG risinÄjuma Ä£enerÄ“tajai atbildei atbilstoÅ¡i jautÄjumi, un Å¡o jautÄjumu vektori tiek salÄ«dzinÄti ar oriÄ£inÄlo jautÄjumu. Platforma RagBench (Friel et al. 2024) RAG risinÄjumus vÄ“rtÄ“, izmantojot Å¡Ädas metrikas: *utilization* â€˜izmantojumsâ€™, kas atspoguÄ¼o to, kÄda daÄ¼a no konteksta tiek izmantota atbildes Ä£enerÄ“Å¡anai; *relevance* â€˜noderÄ«baâ€™, kas parÄda, kÄda daÄ¼a no konteksta vajadzÄ«ga jautÄjuma atbildÄ“Å¡anai; *adherence* â€˜atbilstÄ«baâ€™, kas identificÄ“ halucinÄcijas Ä£enerÄ“tajÄ atbildÄ“; *completeness* â€˜pilnÄ«gumsâ€™, kas parÄda, cik labi Ä£enerÄ“tÄ atbilde ietver derÄ«go konteksta informÄciju. PÄ“tÄ«jumÄ (Chen et al. 2024) tiek izveidota datu kopa RAG vÄ“rtÄ“Å¡anai, kurÄ tiek izmantotas Å¡Ädas metrikas: *accuracy* â€˜akurÄtumsâ€™, kura parÄda, vai Ä£enerÄ“tÄ atbilde sakrÄ«t ar references atbildi; *rejection rate* â€˜noraidÄ«juma mÄ“rsâ€™ â€“ Å¡Ä« metrika mÄ“ra LLM spÄ“ju Ä£enerÄ“t noraidoÅ¡u atbildi, ja tiek izmantots neatbilstoÅ¡s konteksts, kurÄ atbildes nav; *error detection rate* â€˜kÄ¼Å«das noteikÅ¡anas mÄ“rsâ€™ parÄda, vai LLM spÄ“j noteikt faktu kÄ¼Å«das; *error correction rate* â€˜kÄ¼Å«das laboÅ¡anas mÄ“rsâ€™ parÄda, vai LLM spÄ“j labot kÄ¼Å«du un atgriezt pareizu atbildi, ja noteikta faktu kÄ¼Å«da.

MÄ“s izmantojam Å¡Ädas *Ragas* metrikas, kuru aprÄ“Ä·inam nav nepiecieÅ¡ams LLM:

* **BLEU** ir metrika, ko izmanto, lai vÄ“rtÄ“tu Ä£enerÄ“tÄs atbildes kvalitÄti, salÄ«dzinot to ar references atbildi. LÄ«dzÄ«ba starp Ä£enerÄ“to atbildi un references atbildi tiek vÄ“rtÄ“ta, balstoties uz n-grammu precizitÄti un piemÄ“rojot sodu tekstam, kas Ä«sÄks par references tekstu. SÄkotnÄ“ji BLEU rÄdÄ«tÄjs tika izstrÄdÄts maÅ¡Ä«ntulkoÅ¡anas sistÄ“mu vÄ“rtÄ“Å¡anai, taÄu to izmanto arÄ« citos dabiskÄs valodas apstrÄdes uzdevumos. BLEU ir robeÅ¾Äs no 0 lÄ«dz 1, kur 1 nozÄ«mÄ“ pilnÄ«gu atbilstÄ«bu starp Ä£enerÄ“to atbildi un references atbildi.
* **ROUGE** ir metriku kopums, ko izmanto, lai vÄ“rtÄ“tu Ä£enerÄ“tÄs atbildes kvalitÄti, salÄ«dzinot to ar references atbildi. LÄ«dzÄ«ba starp Ä£enerÄ“to atbildi un references atbildi tiek vÄ“rtÄ“ta, balstoties uz n-grammu pÄrklÄjumu, precizitÄti un F1 rÄdÄ«tÄju. ROUGE ir robeÅ¾Äs no 0 lÄ«dz 1, kur 1 nozÄ«mÄ“ pilnÄ«gu atbilstÄ«bu starp Ä£enerÄ“to atbildi un references atbildi.
* **LevenÅ¡teina attÄlums** aprÄ“Ä·ina minimÄlo ievietoÅ¡anas, dzÄ“Å¡anas un aizstÄÅ¡anas operÄciju skaitu, kas nepiecieÅ¡ams, lai vienu virkni pÄrveidotu par otru. NormalizÄ“ta LevenÅ¡teina attÄlums ir robeÅ¾Äs no 0 lÄ«dz 1, kur 1 nozÄ«mÄ“ pilnÄ«gu atbilstÄ«bu starp Ä£enerÄ“to atbildi un references atbildi.
* **SemantiskÄ lÄ«dzÄ«ba** tiek noteikta, aprÄ“Ä·inot kosinusa lÄ«dzÄ«bu starp Ä£enerÄ“tÄs atbildes un references atbildes vektoriem, kas iegÅ«ti ar Hugging Face *paraphrase-multilingual-mpnet-base-v2[[5]](#footnote-6)* vektorizÄ“Å¡anas modeÄ¼a palÄ«dzÄ«bu. LÄ«dzÄ«ba ir robeÅ¾Äs no 0 lÄ«dz 1, kur lielÄka vÄ“rtÄ«ba apzÄ«mÄ“ augstÄku semantisko lÄ«dzÄ«bu starp Ä£enerÄ“to atbildi un references atbildi.

Ir veikti vairÄki atbilÅ¾u Ä£enerÄ“Å¡anas eksperimenti, dodot lielajam valodas modelim ar atÅ¡Ä·irÄ«gÄm metodÄ“m izgÅ«tu kontekstu â€“ 1) fragmenti, kas izgÅ«ti no *TypeSense* vektoru datubÄzes ar vektoru lÄ«dzÄ«bas palÄ«dzÄ«bu, salÄ«dzinot tos ar jautÄjuma vektoru; 2) fragmenti, kas izgÅ«ti gan ar vektoru lÄ«dzÄ«bu, gan meklÄ“jot jautÄjumÄ sastopamos atslÄ“gvÄrdus *TypeSense* datubÄzÄ“; 3) par kontekstu izmantojot failu, kurÄ ir atbilde uz jautÄjumu; 4)Â par kontekstu izmantojot faila fragmentus, kuri daÄ¼Ä“ji automÄtiski tika identificÄ“ti ar LLM palÄ«dzÄ«bu. Eksperimentu rezultÄti redzami 10. tabulÄ. Visos eksperimentos konteksts ir oriÄ£inÄlajÄ, angÄ¼u valodÄ.

TÄ kÄ konteksts visos eksperimentos ir angÄ¼u valodÄ, var novÄ“rot, ka atslÄ“gvÄrdu meklÄ“Å¡ana papildus fragmentu izguvei uz vektoru lÄ«dzÄ«bas pamata bÅ«tiskÄk uzlabo rezultÄtus tikai angÄ¼u valodai. AtslÄ“gvÄrdi tiek izgÅ«ti no uzdotÄ jautÄjuma valodas. TÄtad atslÄ“gvÄrdu izgÅ«Å¡anas metodi nav lietderÄ«gi izmantot, ja konteksta valoda atÅ¡Ä·iras no jautÄjuma valodas.

10. tabula. AtbilÅ¾u Ä£enerÄ“Å¡anas kvalitÄte jautÄjumiem angÄ¼u (EN), latvieÅ¡u (LV), lietuvieÅ¡u (LT) un igauÅ†u (ET) valodÄ

| **Valoda** | **Konteksta izguves metode** | | | **Metrikas** | | | |
| --- | --- | --- | --- | --- | --- | --- | --- |
| **Vektoru lÄ«dzÄ«ba** | **AtslÄ“gvÄrdi** | **Fails** | **BLEU** | **ROUGE** | **LevenÅ¡teina attÄlums(izteikta kÄ lÄ«dzÄ«ba)** | **SemantiskÄ lÄ«dzÄ«ba** |
| EN | - | - | + | **0.5169** | **0.6712** | **0.6280** | **0.8467** |
| EN | - | - | pareizie fragmenti | 0.5020 | 0.6523 | 0.6192 | 0.8360 |
| EN | + | - | - | 0.4835 | 0.6239 | 0.6091 | 0.7805 |
| EN | + | + | - | 0.5124 | 0.6631 | 0.6327 | 0.8282 |
| LV | - | - | + | **0.2654** | 0.4764 | 0.4945 | 0.7692 |
| LV | - | - | pareizie fragmenti | 0.2597 | **0.4869** | **0.5067** | **0.7832** |
| LV | + | - | - | 0.2105 | 0.3690 | 0.4342 | 0.6176 |
| LV | + | + | - | 0.2173 | 0.3746 | 0.4419 | 0.6180 |
| LT | - | - | + | 0.2715 | 0.4916 | 0.5253 | 0.8024 |
| LT | - | - | pareizie fragmenti | **0.2807** | **0.4977** | **0.5325** | **0.8078** |
| LT | + | - | - | 0.2318 | 0.3912 | 0.4681 | 0.6542 |
| LT | + | + | - | 0.2341 | 0.3944 | 0.4655 | 0.6581 |
| ET | - | - | + | 0.2540 | 0.4688 | 0.4901 | 0.7723 |
| ET | - | - | pareizie fragmenti | **0.2699** | **0.4789** | **0.5024** | **0.7796** |
| ET | + | - | - | 0.2258 | 0.3787 | 0.4452 | 0.6263 |
| ET | + | + | - | 0.2312 | 0.3928 | 0.4566 | 0.6364 |

Metrikas, kuras izmanto LLM, Å¡ajos eksperimentos netiek izmantotas. Å o metriku trÅ«kums ir mainÄ«gÄ rezultÄtu ticamÄ«ba. DaÅ¾Ädu LLM modeÄ¼u rezultÄti var atÅ¡Ä·irties. ModeÄ¼i mÄ“dz neievÄ“rot instrukcijas uzvednÄ“, piemÄ“ram, ja uzvednÄ“ ir teikts atgriezt rezultÄtus JSON formÄtÄ, modelis ne vienmÄ“r to ievÄ“ro. LLM atbildes mÄ“dz bÅ«t izsmeÄ¼oÅ¡Äkas par references atbildÄ“m. PiemÄ“ram, paplaÅ¡inÄtÄ references atbilde uz jautÄjumu â€œ*Where was Volta born?â€* â€˜Kur ir dzimis Volta?â€™ ir â€œ*Volta was born in Como.â€* â€˜Volta ir dzimis Komo.â€™ KontekstÄ balstÄ«ta LLM atbilde ir â€œ*Volta was born in Como, Italy.â€* â€˜Volta ir dzimis Komo, ItÄlijÄâ€™. Å Äda atbilde atbilst kontekstam, taÄu salÄ«dzinÄjumÄ ar references atbildi tajÄ ir par vienu faktu vairÄk, tÄdÄ“Ä¼ LLM metrika Å¡Ädu atbildi vÄ“rtÄ“ negatÄ«vi, kaut gan cilvÄ“kvÄ“rtÄ“jumÄ Å¡Äda atbilde bÅ«tu vÄ“rtÄ“jama pozitÄ«vi.

Izmantojot OpenAI *GPT-4o* modeli caur Microsoft Azure platformu, ir ierobeÅ¾ojumi izsaukumu skaitam minÅ«tÄ“ un apstrÄdÄto vÄrddaÄ¼u skaitam minÅ«tÄ“, tÄdÄ“Ä¼ Å¡is modelis nav piemÄ“rots automÄtisku testu izpildei. KomerciÄlu modeÄ¼u izmantoÅ¡ana lielu testa datu kopu vÄ“rtÄ“Å¡anai ir ierobeÅ¾ota arÄ« izmaksu dÄ“Ä¼.

1. DaÅ¾Ädu lielo valodas modeÄ¼u atbilÅ¾u Ä£enerÄ“Å¡anas kvalitÄtes salÄ«dzinÄjums
   1. Atbildes izvÄ“le no vairÄkiem variantiem

Atbildes izvÄ“les uzdevumÄ modelim tiek dots jautÄjums ar vairÄkiem atbilÅ¾u variantiem. ModeÄ¼a uzdevums ir atgriezt pareizÄs atbildes identifikatoru. Å im uzdevumam mÄ“s izmantojam divas datu kopas - Belebele[[6]](#footnote-7) un Klokan-QA. Belebele datu kopÄ ir iekÄ¼auti dati 122 valodÄs. TajÄ ir 900 jautÄjumi, kas saistÄ«ti ar nelieliem teksta fragmentiem no FLORES-200 datu kopas. JautÄjumi ir par 488 teksta fragmentiem. Katram jautÄjumam ir vairÄkas atbildes, no kurÄm tikai viena ir pareiza. Klokan-QA datu kopa ir Äehu valodÄ. Klokan-QA datu kopÄ ir 4053 jautÄjumi no matemÄtikas olimpiÄdÄ“m. Katram jautÄjumam ir pieci atbilÅ¾u varianti.

Å im uzdevumam tiek lietota bezpiemÄ“ru uzvedne angÄ¼u valodÄ (konteksts â€œ{context}â€, jautÄjums â€œ{question}â€ un atbilde â€œ{answer\_#}â€ ir kÄdÄ no eksperimentos izmantotajÄm valodÄm):

*This is the context: '{context}'. This is the question: '{question}'. Here are the 4 candidate answers: '1) {answer\_1}'; '2) {answer\_2}'; '3) {answer\_3}'; '4) {answer\_4}'. Report only the correct answer's ID (1, 2, 3, or 4) using the mandatory JSON format: {answer\_id: ""}.*

RezultÄtu vÄ“rtÄ“Å¡anai tiek izmantota precizitÄtes metrika, kas raksturo pareizo atbilÅ¾u attiecÄ«bu pret visÄm atbildÄ“m. Katrs eksperiments tika veikts divas reizes ar katru valodas modeli. 11. tabulÄ atspoguÄ¼oti vidÄ“jie rezultÄti no katra eksperimenta.

11. tabula. Atbildes izvÄ“les uzdevuma precizitÄte daÅ¾Ädiem valodas modeÄ¼iem un valodÄm

| **Datu kopa** | **valoda** | **gpt-3.5-turbo** | **gpt-4** | **gpt-4o** | **llama3** | **llama3:70b** | **llama3.1** | **llama3.1:70b** | **llama3.2** | **gemma2** | **gemma2:27b** | **mistral-nemo:12b** | **phi3:14b** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Belebele | en | 0.903 | 0.960 | 0.962 | 0.883 | 0.938 | 0.872 | 0.947 | 0.740 | 0.931 | 0.943 | 0.898 | 0.886 |
| cs | 0.818 | 0.928 | 0.937 | 0.769 | 0.888 | 0.743 | 0.892 | 0.676 | 0.907 | 0.910 | 0.800 | 0.296 |
| et | 0.773 | 0.920 | 0.928 | 0.576 | 0.770 | 0.560 | 0.821 | 0.397 | 0.859 | 0.893 | 0.686 | 0.003 |
| lt | 0.734 | 0.900 | 0.941 | 0.607 | 0.768 | 0.618 | 0.834 | 0.435 | 0.861 | 0.898 | 0.715 | 0.001 |
| lv | 0.756 | 0.929 | 0.950 | 0.571 | 0.710 | 0.581 | 0.783 | 0.410 | 0.869 | 0.914 | 0.689 | 0.002 |
| Klokan-QA | cs | 0.256 | 0.175 | 0.290 | 0.216 | 0.304 | 0.232 | 0.260 | 0.216 | 0.279 | 0.265 | 0.222 |  |

RezultÄti ir lÄ«dzÄ«gi maÅ¡Ä«ntulkoÅ¡anas uzdevuma rezultÄtiem. VisaugstÄko precizitÄti uzrÄda *GPT-4o* un *GPT-4* modelis, kuriem seko *gemma* modeÄ¼i un *Llama3.1:70b*. AngÄ¼u valodai *Llama3.1:70b* ir nedaudz labÄks par *Gemma2:27b*. *Phi* modelis ne-angÄ¼u valodÄm bieÅ¾i vien vispÄr nespÄ“ja Ä£enerÄ“t rezultÄtu JSON formÄtÄ.

Eksperimenti ar nekvantÄ“tiem modeÄ¼iem atspoguÄ¼oti 12. tabulÄ. SecinÄjumi ir lÄ«dzÄ«gi â€“ nekvantÄ“tiem modeÄ¼iem ir augstÄka precizitÄte, taÄu tÄ nepÄrsniedz *GPT-4o*.

12. tabula. Atbildes izvÄ“les uzdevuma precizitÄte daÅ¾Ädiem kvantÄ“tiem un nekvantÄ“tiem valodas modeÄ¼iem un valodÄm

| **Valoda** | **GPT-4o** | **Llama3.1** | **Llama3.1:8b-instruct-fp16** | **Llama3.1:70b** | **Llama3.1:70b-instruct-fp16** | **Llama3.2** | **Llama3.2:3b-instruct-fp16** | **Gemma2** | **gemma2:9b-instruct-fp16** | **gemma2:27b** | **Gemma2:27b-instruct-fp16** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| en | 0.960 | 0.872 | 0.910 | 0.947 | 0.956 | 0.740 | 0.725 | 0.931 | 0.932 | 0.943 | 0.939 |
| cs | 0.928 | 0.743 | 0.828 | 0.892 | 0.916 | 0.676 | 0.648 | 0.907 | 0.910 | 0.910 | 0.916 |
| et | 0.920 | 0.560 | 0.698 | 0.821 | 0.903 | 0.397 | 0.428 | 0.859 | 0.870 | 0.893 | 0.892 |
| lt | 0.900 | 0.618 | 0.731 | 0.834 | 0.892 | 0.435 | 0.463 | 0.861 | 0.886 | 0.898 | 0.892 |
| lv | 0.929 | 0.581 | 0.708 | 0.783 | 0.899 | 0.410 | 0.412 | 0.869 | 0.881 | 0.914 | 0.918 |

* 1. Atbildes Ä£enerÄ“Å¡ana, izmantojot modeÄ¼a iekÅ¡Ä“jÄs zinÄÅ¡anas

Lai salÄ«dzinÄtu daÅ¾Ädu modeÄ¼u Ä£enerÄ“tu atbilÅ¾u kvalitÄti, tika sagatavoti 10 jautÄjumi latvieÅ¡u un lietuvieÅ¡u (sk. 13. tabulu) valodÄ par literatÅ«ru, vÄ“sturi, loÄ£iku un Ä£eogrÄfiju.

13. tabula. 10 jautÄjumi latvieÅ¡u un lietuvieÅ¡u valodÄ

| **Latviski** | **Lietuviski** |
| --- | --- |
| Kas ir vienÄ«gais no septiÅ†iem senÄs pasaules brÄ«numiem, kas ir saglabÄjies lÄ«dz mÅ«sdienÄm, un kur tas atrodas? | Koks vienintelis iÅ¡ 7 senovÄ—s pasaulio stebuklÅ³, iÅ¡likÄ™s iki Å¡iÅ³ dienÅ³ ir kur jis randasi? |
| Kad sabruka Padomju SavienÄ«ba, cik jaunas valstis tika izveidotas, un kÄ tÄs sauc? | Kada Å¾lugo SovietÅ³ SÄ…junga, kiek naujÅ³ Å¡aliÅ³ atsirado ir kokie jÅ³ pavadinimai? |
| KÄdi ir globÄlÄs sasilÅ¡anas galvenie cÄ“loÅ†i, un kÄdi pasÄkumi var mazinÄt tÄs ietekmi? | Kokios yra pagrindinÄ—s visuotinio atÅ¡ilimo prieÅ¾astys ir kokios priemonÄ—s galÄ—tÅ³ suÅ¡velninti jo poveikÄ¯? |
| Vai vari nosaukt vismaz vienu valodu no katras no Å¡Ä«m pirmvalodu grupÄm: baltu, slÄvu, Ä£ermÄÅ†u un somugru, un norÄdÄ«t, kura valoda pieder kurai grupai? | Pateikite bent vienÄ… kalbos, priklausanÄios kiekvienai iÅ¡ baltÅ³, slavÅ³, germanÅ³ ir finougrÅ³ prokalbiÅ³, pavyzdÄ¯, nurodykite kuri kalba kuriai prokalbei priklauso. |
| Vai vari nosaukt mÄkslÄ«gÄ intelekta definÄ«ciju? | Pateikite dirbtinio intelekto apibrÄ—Å¾imÄ… |
| PÄ“rtiÄ·is, vÄvere un putns sacenÅ¡as, kurÅ¡ pirmais nonÄks kokosriekstu koka virsotnÄ“. KurÅ¡ pirmais sasniegs banÄnu? | BeÅ¾dÅ¾ionÄ—, voverÄ— ir paukÅ¡tis bando pasiekti kokoso palmÄ—s virÅ¡Å«nÄ™. Kuris pirmas nuskins bananÄ…? |
| Kas ir augstÄkÄ virsotne EiropÄ, un vai vari sniegt plaÅ¡Äku informÄciju par tÄ atraÅ¡anÄs vietu, augstumu un nozÄ«mi? | Koks yra aukÅ¡Äiausias kalnas Europoje? Pateikite iÅ¡samiÄ… informacijÄ… apie jo vietÄ…, aukÅ¡tÄ¯ ir reikÅ¡mÄ™. |
| Kas ir fotosintÄ“zes process, un kÄpÄ“c tas ir bÅ«tisks dzÄ«vei uz zemes? | Kas yra fotosintezÄ— ir kodÄ—l Å¡is procesas toks svarbus gyvybei Å½emÄ—je? |
| Ko vari pastÄstÄ«t par relativitÄtes teoriju? | KÄ… galite pasakyti apie reliatyvumo teorijÄ…? |
| KÄdas tÄ“mas tiek apskatÄ«tas DÅ¾ordÅ¾a Orvela darbÄ â€œDzÄ«vnieku fermaâ€ un kÄpÄ“c tÄs ir aktuÄlas arÄ« mÅ«sdienÄs? | Kokios temos gvildenamos DÅ¾ordÅ¾o Orvelo â€GyvuliÅ³ Å«kisâ€œ ir kodÄ—l jos iÅ¡lieka aktualios Å¡iandien? |

Lielajiem valodas modeÄ¼iem tika dota vienkÄrÅ¡a uzvedne jautÄjuma valodÄ, kas prasÄ«ja atbildÄ“t uz jautÄjumu. Atbildes vÄ“rtÄ“ja divi latvieÅ¡u un lietuvieÅ¡u valodas eksperti. Tika vÄ“rtÄ“ti gramatiski nepareizi vÄrdi, nepareizas locÄ«jumu formas un izdomÄti vÄrdi (vÄrdi, kÄdu valodÄ nav, bet kuri iederas valodas gramatiskajÄ sistÄ“mÄ). Ja teikuma (vai frÄzes) uzbÅ«ve neatbilda valodas normÄm, par kÄ¼Å«dainiem tika uzskatÄ«ti visi vÄrdi. RezultÄti latvieÅ¡u valodai ir skatÄmi 2. un 3. attÄ“lÄ. LietuvieÅ¡u valodas rezultÄti ir skatÄmi 4. un 5. attÄ“lÄ. ApzÄ«mÄ“jums *const* reprezentÄ“ nepareizu sintaktisko konstrukciju skaitu, *err* apzÄ«mÄ“ kÄ¼Å«du skaitu (iekÄ¼aujot gramatikas kÄ¼Å«das, nepareizas vÄrdu galotnes, nepareizi izvÄ“lÄ“tus vÄrdus), *invent* apzÄ«mÄ“ izgudrotu vÄrdu skaitu un *total* apzÄ«mÄ“ visu kÄ¼Å«du skaitu.

2. attÄ“ls. VidÄ“jais kÄ¼Å«du skaits starp 100 vÄrdiem latvieÅ¡u valodÄ

3. attÄ“ls. VidÄ“jais kÄ¼Å«du skaits teikumÄ latvieÅ¡u valodai

4. attÄ“ls. VidÄ“jais kÄ¼Å«du skaits starp 100 vÄrdiem lietuvieÅ¡u valodÄ

5. attÄ“ls. VidÄ“jais kÄ¼Å«du skaits teikumÄ lietuvieÅ¡u valodai

KvalitatÄ«vÄ analÄ«ze liecina, ka vislabÄkos rezultÄtus latvieÅ¡u valodai uzrÄda *GPT-4o* modelis. Å Ä« modeÄ¼a Ä£enerÄ“tajos tekstos ir vismazÄk valodai neatbilstoÅ¡u sintaktisko konstrukciju un vismazÄk gramatikas kÄ¼Å«du. LietuvieÅ¡u valodai labÄki par *GPT-4o* rezultÄtiem ir vienvalodas lietuvieÅ¡u valodas modeÄ¼i *Lt-Llama2-7b-instruct* un *Lt-Llama2-13b-instruct*.

Å ajÄ eksperimentÄ tika vÄ“rtÄ“ta arÄ« atbilÅ¾u atbilstÄ«ba jautÄjumam (sk. 14. tabulu).

14. tabula. JautÄjumam atbilstoÅ¡u atbilÅ¾u skaits

| **Modelis** | **LatvieÅ¡u** | **LietuvieÅ¡u** |
| --- | --- | --- |
| llama3.1 | 3 (30%) | 2 (20%) |
| llama3.1:70b | 9 (90%) | 9 (90%) |
| gemma2:27b | 8 (80%) | 9 (90%) |
| gpt-4o | 10 (100%) | 9 (90%) |
| Lt-Llama2-7b-instruct | - | 5 (50%) |
| Lt-Llama2-13b-instruct | - | 4 (40%) |

ModeÄ¼u vÄ“rtÄ“jums valodas kÄ¼Å«du ziÅ†Ä ir lÄ«dzÄ«gs atbilÅ¾u satura vÄ“rtÄ“jumam, izÅ†emot vienvalodas lietuvieÅ¡u valodas modeÄ¼us. Å ie modeÄ¼i spÄ“j Ä£enerÄ“t lietuvieÅ¡u valodas normÄm atbilstoÅ¡u tekstu, taÄu nespÄ“j adekvÄti atbildÄ“t uz jautÄjumiem. Å o modeÄ¼u spÄ“ja ievÄ“rot instrukcijas ir to trÅ«kums. JautÄjumu atbildÄ“Å¡anas uzdevumÄ nelielas gramatiskas vai strukturÄlas kÄ¼Å«das ir pieÄ¼aujamas, ja vien Ä£enerÄ“tÄ informÄcija ir korekta.

Eksperimenta rezultÄti liecina, ka kÄ alternatÄ«vas komerciÄlajam *GPT-4o* modelim ir iespÄ“jams lietot kÄdu no brÄ«vpieejas modeÄ¼iem - *gemma2:27b* vai *llama3.1:70b*.

1. SecinÄjumi

PÄ“tÄ«jumÄ iegÅ«tie rezultÄti Ä¼auj secinÄt, ka pÄ“tniecÄ«bas projekta 2. aktivitÄtes mÄ“rÄ·i ir sasniegti. NozÄ«mÄ«ga loma RAG risinÄjumÄ ir precÄ«zu uzvedÅ†u izmantoÅ¡anai, kas sniedz lielajam valodas modelim norÄdÄ«jumus, kÄdam bÅ«tu jÄbÅ«t Ä£enerÄ“tajam tekstam. PÄ“tÄ«juma ietvaros esam aplÅ«kojuÅ¡i daÅ¾Äda veida uzvednes gan sarunas uzturÄ“Å¡anai, gan daÅ¾Ädu palÄ«guzdevumu veikÅ¡anai â€“ teksta tulkoÅ¡anai, jautÄjumu klasificÄ“Å¡anai, kopsavilkuma veidoÅ¡anai, SQL vaicÄjumu Ä£enerÄ“Å¡anai un citiem uzdevumiem. Å ajÄ pÄ“tÄ«jumÄ veiktie salÄ«dzinoÅ¡ie eksperimenti sniedz ieskatu daÅ¾Ädu lielo valodas modeÄ¼u teksta Ä£enerÄ“Å¡anas kvalitÄtÄ“ maÅ¡Ä«ntulkoÅ¡anas, atbilÅ¾u izvÄ“les un atbilÅ¾u Ä£enerÄ“Å¡anas uzdevumos, Ä«paÅ¡u uzmanÄ«bu pievÄ“rÅ¡ot baltu valodÄm. PÄ“tÄ«jumÄ ir iekÄ¼auta salÄ«dzinoÅ¡a analÄ«ze arÄ« tÄdÄm mazÄk atbalstÄ«tÄm valodÄm, kÄ igauÅ†u (tulkoÅ¡anas un kontekstÄ balstÄ«tas atbildes Ä£enerÄ“Å¡anas uzdevumam) un Äehu (tulkoÅ¡anas uzdevumam). KontekstÄ balstÄ«tu atbilÅ¾u Ä£enerÄ“Å¡anas eksperimentos ir apzinÄtas metrikas (BLEU, ROUGE, LevenÅ¡teina attÄlums, vektoru semantiskÄ lÄ«dzÄ«ba), ar kurÄm var vÄ“rtÄ“t atbilÅ¾u Ä£enerÄ“Å¡anas kvalitÄti. Ä¢enerÄ“Å¡anas kvalitÄtes vÄ“rtÄ“Å¡anai eksperimentos esam izvÄ“lÄ“juÅ¡ie metrikas, kas neizmanto LLM. Esam izpÄ“tÄ«juÅ¡i arÄ« metriku grupu, kuras izmanto LLM. Å o metriku trÅ«kums ir mainÄ«gÄ rezultÄtu ticamÄ«ba. DaÅ¾Ädu LLM modeÄ¼u rezultÄti var atÅ¡Ä·irties. KomerciÄlu modeÄ¼u izmantoÅ¡ana lielu testa datu kopu vÄ“rtÄ“Å¡anai ir ierobeÅ¾ota izmaksu dÄ“Ä¼.

MaÅ¡Ä«ntulkoÅ¡anas eksperimentos tika pÄrbaudÄ«tas gan nekvantÄ“tas daudzvalodu modeÄ¼u versijas, gan Å¡o modeÄ¼u kvantÄ“tas versijas. Abos gadÄ«jumos *GPT-4o* uzrÄdÄ«ja labÄkos rezultÄtus daÅ¾ÄdÄm valodÄm. Lai gan *GPT-4o* nav Ä«paÅ¡i trenÄ“ts maÅ¡Ä«ntulkoÅ¡anas uzdevumiem, tomÄ“r tÄ rezultÄtu kvalitÄte ir tuva specializÄ“to maÅ¡Ä«ntulkoÅ¡anas pakalpojumu, piemÄ“ram, *DeepL*, kvalitÄtei.

RezultÄti rÄda, ka arÄ« brÄ«vpieejas modeÄ¼i, Ä«paÅ¡i *Gemma2:27b* un *Llama3.1:70b*, uzrÄda labus rezultÄtus pÄrbaudÄ«tajos NLP uzdevumos un valodÄs. Å ie modeÄ¼i labi darbojÄs ne tikai maÅ¡Ä«ntulkoÅ¡anÄ un atbilÅ¾u variantu atlases uzdevumos, bet arÄ« spÄ“j Ä£enerÄ“t tekstu bez kritiskÄm gramatikas un teksta uzbÅ«ves kÄ¼Å«dÄm. No tÄ var secinÄt, ka brÄ«vpieejas modeÄ¼i ir pieÅ†emama alternatÄ«va, ja GPT modeÄ¼u izmantoÅ¡ana ir ierobeÅ¾ota privÄtuma apsvÄ“rumu dÄ“Ä¼ vai izmaksu ierobeÅ¾ojumu dÄ“Ä¼.

1. IzmantotÄs literatÅ«ras saraksts

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. *Advances in neural information processing systems*, 33, 1877-1901.

Chen, J., Lin, H., Han, X., & Sun, L. (2024, March). Benchmarking large language models in retrieval-augmented generation. InÂ *Proceedings of the AAAI Conference on Artificial Intelligence*Â (Vol. 38, No. 16, pp. 17754-17762).

Es, S., James, J., Anke, L. E., & Schockaert, S. (2024, March). Ragas: Automated evaluation of retrieval augmented generation. InÂ *Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations*Â (pp. 150-158).

Friel, R., Belyi, M., & Sanyal, A. (2024). Ragbench: Explainable benchmark for retrieval-augmented generation systems.Â *arXiv preprint arXiv:2407.11005*.

Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask learners.Â *OpenAI blog*,Â *1*(8), 9.

Sahoo, P., Singh, A. K., Saha, S., Jain, V., Mondal, S., & Chadha, A. (2024). A systematic survey of prompt engineering in large language models: Techniques and applications.Â *arXiv preprint arXiv:2402.07927*.

Schulhoff, S., Ilie, M., Balepur, N., Kahadze, K., Liu, A., Si, C., ... & Resnik, P. (2024). The prompt report: A systematic survey of prompting techniques. arXiv preprint arXiv:2406.06608.

Zhu, K., Luo, Y., Xu, D., Wang, R., Yu, S., Wang, S., ... & Sun, M. (2024). Rageval: Scenario specific rag evaluation dataset generation framework. *arXiv preprint arXiv:2408.01262*.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models.Â *Advances in neural information processing systems*,Â 35, 24824-24837.

1. https://github.com/ollama/ollama [â†‘](#footnote-ref-2)
2. <https://huggingface.co/neurotechnology/Lt-Llama-2-7b-hf> [â†‘](#footnote-ref-3)
3. <https://huggingface.co/neurotechnology/Lt-Llama-2-13b-instruct-hf> [â†‘](#footnote-ref-4)
4. <https://github.com/facebookresearch/flores/tree/main/flores200> [â†‘](#footnote-ref-5)
5. https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2 [â†‘](#footnote-ref-6)
6. <https://github.com/facebookresearch/belebele?tab=readme-ov-file> [â†‘](#footnote-ref-7)