Learning with LLMs: Supporting complex reasoning, planning and argumentation, applied to providing educational guidance.
   
Despite their impressive performance on a wide variety of tasks, Large Language Models (LLMs) fall short on tasks that involve complex reasoning, argumentation and planning. The aim of this macro-project is (i) to investigate how LLMs can assist humans in complex reasoning and argumentation (Task 1); (ii) to extend LLMs with a modular architecture of symbolic components to enable planning and reasoning (Task 2); and (iii) validate this architecture in providing guidance on educational pathways, which will require reasoning and planning capabilities (Task 3). 

Task 1 will be led by Prof. Yvonne Rogers (UCL), task 2 by Prof. Frank van Harmelen (VUA) and Prof. John Shawe-Taylor (UCL) and task 3 by Prof. John Shawe-Taylor & Prof. Yvonne Rogers (UCL). Other partners participating in the project are:
* Marko Grobelnik, (JSI), in task 2 extraction of logical information using LLMs and engaging with the new language model project. 
* Andrea Galassi and Paolo Torroni, (Bologna), contributing to tasks 1 and 2,
* Zelun Tony Zhang (Fortiss) contributing to tasks 1 and 3,
* Davor Orlic (Optimal AI Research) contributing to task 4,
* Marco Lippi (external) (University of Modena and Reggio Emilia (until 28 Feb), University of Florence (from 1 March) in tasks 1 and 2.


Task 1 [1-6 months]: Evaluating LLMs argumentation capabilities

The first step of our macro project proposal will investigate whether and how the new paradigm of generative AI and specifically LLMs can help humans (in this case, students) to learn to reason and debate about solutions to complex problems, such as sustainability challenges, where there are often lots of trade-offs to consider. These complex topics will serve as a testbed to help assess LLMs capabilities in multiple dimensions: mapping knowledge, linking arguments, embedding semantics and capturing evidence. Our overarching goal is studying the capabilities of LLMs in supporting human reasoning and debating skills, evaluating whether they can bring facts, statistics, opinions, answers and debating directions which are enriching and support different perspectives.  
We will investigate how and whether LLMs can be used as a way of bringing viewpoints that are perhaps crucial to the debate but not present in a discussion. For example, while wind turbines are a suitable solution for the future of decarbonisation, they often create harm for bird and insect populations when onshore. In contrast, if offshore, they create biodiversity safe havens, as fishing and ship circulation is not allowed. Recycling of the materials of the blades is extremely complex, so they contribute significantly to product waste. In land, they also compete with space for agriculture. Onshore, one can build very large turbines that maximise energy output, but the infrastructure under the sea is much more complex, increasing the required investment. 
We will develop a user study around a series of well-studied complex challenges related to sustainability and set up a range of exercises where participants are asked to use chatGTP4, Bard or other models to find the evidence and then reason with the chatbot to develop a set of arguments. The participants will then have to explain the different points of view in their reasoning. 
 
We will initially run a study with experts to determine how good chatGPT is at coming up with different sides of a debate and how those can be put together for humans to reason with. We will then run a user study to see the extent to which chatGPT can be put to the test to help students learn to reason better, themselves, using LLMs as a learning tool. 

We also propose to develop and apply methods to automatically evaluate and compare the text produced by an LLM on a controversial topic and the text produced by humans, either relying on existing resources or those produced by the macro project.

Task 2 [1-12 months]: Including reasoning in conjunction with LLMs
 	 	 	 	
The task will investigate the power of including reasoning in conjunction with LLMs in order to enable human-centric AI, that is an AI system able to interact fluidly with a user in order to understand more clearly their interests and hence provide them with relevant feedback or content. LLMs are themselves only able at best to perform elementary reasoning and lack the ability to update their models based on data learned or received through interactions with users. We propose to address these shortcomings through two routes:
Symbolic short-term memory: Enrich LLMs with a structured short-term memory where the system can update its state to reflect the new knowledge or inferences; This is different from the current approach of few-shot learning through prompting, which is based on the context buffer in the transformer architectures. In a loose analogy to the human memory system, current transient memory of LLMs is analogous to the human short-term memory, where we intend to enrich the LLMs with something analogous to working memory: larger, less transient, and more richly structured than short term memory, but much less permanent than long term memory. 
Society of minds: Let LLMs interact with external modules that execute tasks for which LLMs are not well-suited, such as looking up factual data, performing computations, or drawing logical inferences. This approach is currently gaining traction as “Augmented Language Models” (https://arxiv.org/abs/2302.07842).  This would change the monolithic LLM architecture into a “society of minds” with specialised modules, some of which will be based on latent representation, while others will use explicitly structured symbolic representations. We aim to go beyond the currently fashionable Toolformer architecture (https://arxiv.org/abs/2302.04761) by allowing a much richer control structure between the modules than simply having the LLM call out to the other modules. Forms of tractable inference that will be relevant for the educational guidance scenario are ontological inference and constrained-based inference.  

We also propose to develop and apply methods to recognize argumentative components automatically. These components can be (among the) key elements that will be stored and accessed in the “symbolic short-term memory”, since they provide a concise representation of what the model knows (e.g., premises) and the consequent inferences (e.g., claims). These Argument Mining methods can also play a role in the development of the “society of minds” either as specifically dedicated modules or integrated into other ones.


Task 3 [5-12 months]: Tracking and evaluating through user experience in educational guidance

The system infers learners’ skills by observing their ability to absorb educational material and thereby updating a sparse skill vector per user, indexed by Wikipedia pages. Educational materials can be mapped into this representation by a process known as Wikification. The reasoning modules will enable individual learners to discuss their interests and skills with the system. The frame for these discussions will be narratives relating to learning trajectories.
An LLM also can be used to refine the recommender’s understanding of the user in multiple ways. 1) In the cold start scenario, an initial conversation by the LLM with the user will help a personalisation model to identify a set of Wikipedia topics a user is interested in. This set can be used as the initial seed concepts for generating recommendations until a reliable learner model is built with user interactions. 2) Alternatively, LLMs can generate educational questions that can be used to verify the skill representation built by the system and track lerners’ progress. In both techniques, the LLM acts as the bridge between a sub-symbolic machine learning model and a human learner who have to communicate with each other to succeed. The quality of the user experience can be measured with user studies and learner engagement analysis. (Task 3 below). To understand the efficacy of the use of LLMs for automatic tracking of learners’ progress Tilde will develop a solution that generates content-based questions of course materials (with the help of an LLM) and analyses student responses to these questions (with the help of an LLM), thereby enabling automated testing of student knowledge and learning progress. The solution will be integrated in Tilde’s virtual assistant technology that will allow showcasing and also evaluating the technologies efficacy. 
The macro-project will exploit the X5gon infrastructure, an internet scale system that indexes educational material based on the Wikification referred to above. It will also develop the X5learn architecture enacting the user modelling. The recently developed TrueLearn python library (https://truelearn.readthedocs.io/en/latest/), a byproduct of a previous HumaneAI micro project, can be used for this. The enrichment system of the X5gon system will be deployed using docker containerisation technology that ensures different modules can be added or replaced with alternative implementations to allow modular development and testing as well as scaling. In this way the project is open to different sites participating addressing different functionalities required or desirable for the overall project.
A second pillar of application will be in financial investment advice. This will be lead by Fortiss who has experience and existing systems in this space. They would conceptualize the decision support tool (DST) design and implementation as well as conducting a user study evaluation in this task.

The final thrust of the project is tracking and studying user experience and the influence of different programmatic elements in influencing the effectiveness of the communication and resulting recommendations. The goal of these studies will be capturing the degree to which the system empowers users, hence creating a human-centric AI. The intention is to generate datasets that can be used to study and optimise these outcomes in offline settings, hence accelerating progress before retesting with real users. 
Task 4 [1-12 months]: Dissemination, Outreach, and Business Creation
This task focuses on the dissemination and outreach activities for the project. The aim is to effectively communicate project results, engage with relevant stakeholders, and explore business creation opportunities based on the project outcomes. This task can also run across all macro-projects.
Key Objectives: 
* Dissemination and outreach, 
* Business Creation 
* Community and stakeholder engagement.
Deliverables:  
* Dissemination Report: Document detailing dissemination activities, reach, and impact.
* Business Plan: A comprehensive business plan for deploying LLM technologies in educational contexts, including market analysis, business model, and commercialization strategy.
* Stakeholder Engagement Summary: A report summarizing the feedback and interest of the consortium and industrial partners, along with potential collaboration or implementation plans.

Appendix: Example envisioned dialogue
We illustrate how this new architecture would function in a machine-assisted learning setting: .
AIstein: I see you are getting interested in machine learning but have yet to grasp the challenges of data cleaning. Would that be of interest to you?
LLMs will be used both to generate appropriate statements and questions such as that given in the example above, as well as to process the responses to infer the appropriate narrative and instantiate some of its variables, hence creating an appropriate frame for the discussion and performing inference in that frame, eg
User: I would prefer to cover more technical issues before getting into practical data processing.
AIstein: Data cleaning can wait, but sometimes doing something practical is the best way to learn – if you like, I can show you a short introduction, so you know what you’re missing. Alternatively, you could try to learn about the different types of machine learning, from classification through to reinforcement learning. Do you have a target application in mind?
Here there are various narratives being considered:
1. the user has a data processing challenge and has been studying machine learning in order to address that challenge;
2. the user has set him or herself the goal of mastering the topic of machine 	learning more broadly;
The final question is still ambivalent on this question but will provide good insights into both narratives as well as helping to decide which is more appropriate. In addition to the reasoning model and the skills representation, there is a wrapper that must balance exploration and exploitation in order to determine the most appropriate narrative and instantiate its variables so as to identify the most useful content for the user.





